= Kafka Streams API: Шаг за рамки Hello World
Иван Пономарёв, КУРС/МФТИ
:revealjs_theme: black
:revealjs_customtheme: white_course.css
:revealjs_slideNumber:
:revealjs_history:
:revealjs_progress:
:encoding: UTF-8
:lang: ru
include::_doc_general_attributes.adoc[]
:doctype: article
:toclevels: 3
:imagesdir: images
:source-highlighter: pygments
//:highlightjsdir: highlight
:icons: font
:iconfont-remote!:
:iconfont-name: font-awesome-4.7.0/css/font-awesome
:revealjs_mouseWheel: true
:revealjs_center: false
:revealjs_transition: none
:revealjs_width: 1600
:revealjs_height: 900


//== Часть 1. Введение
:!figure-caption:

ponomarev@corchestra.ru

icon:twitter[size=lg] @inponomarev

[%notitle]
== Кто я такой

[cols="30a,70a"]
|===
.^|image::me.jpg[]
.^|
* Tech Lead at KURS
* ERP systems & Java background
* Speaker at JPoint, Devoops, Heisenbug, JUG.MSK, PermDevDay, DevopsForum, Стачка etc.
* Текущий проект: Real-time Webscraping
|===

[%notitle]
== Наш опенсорс: Celesta & 2bass

[cols="45a,35a"]
|===
.^|
image::celesta_duke.png[]
.^|
image::bass_duke.png[]
|===

== Celesta & 2bass -- хабрапосты:

* https://habr.com/ru/post/337816/[Миграция схемы данных без головной боли: идемпотентность и конвергентность для DDL-скриптов]
* https://habr.com/ru/post/455746/[Celesta 7.x: ORM, миграции и тестирование «в одном флаконе»]

image::migration.png[]

== Celesta 7.x

* Только Java (отказались от Jython)
* Maven Plugin 
* JUnit5 extension
* Spring Boot Starter

== Всё, что я показываю, есть на гитхабе

[cols="30a,70a"]
|===
.^|image::octocat.jpg[]
.^|
* Слайды: https://inponomarev.github.io/kstreams-examples[inponomarev.github.io/kstreams-examples]

* Исходники: https://github.com/inponomarev/kstreams-examples[github.com/inponomarev/kstreams-examples]
|===


[transition="fade-out, slide-in"]
== Зачем нам Kafka?

image::kafka.jpg[{image-30-width}]

[transition="fade-in, fade-out"]
== Зачем нам Kafka?

[%step]
* Web-scraping в реальном времени
* 500 запросов/сек (да, это очень мало!)
* Удобные штуки «из коробки»:
** Персистентный, но «подрезаемый» лог
** Microbatching

== Зачем нам Streams API?

[%step]
* Real-time stream processing
* Stream-like API (map / reduce)
* Под капотом:
** Ребалансировка
** Внутреннее состояние обработчиков (репликация)
** Легкое масштабирование

== Disclaimer #1: предполагается базовое понимание Кафки

* https://www.youtube.com/watch?v=ztsnkyaIO64[Виктор Гамов — Все стримы ведут в Кафку (jug.msk.ru 23/04/2018)]

* https://www.youtube.com/watch?v=PgoRuxKqStI[Виктор Гамов — Kafka Streams IQ: «Зачем нам база данных?» (jug.msk.ru 08/05/2019)]

== Disclaimer #2: доклад не о жизни в production!

Доклады о жизни в production:

* https://www.youtube.com/watch?v=A_yUaPARv8U[Григорий Кошелев — Когда всё пошло по Кафке (JPoint 2019)]
* https://www.youtube.com/watch?v=wCCR1Tkxc-s[Никита Сальников-Тарновский — Streaming architecture — шаг за рамки примеров кода (devclub.eu 2019.03.26)]


== Kafka за 30 секунд
.Источник: Kafka. The Definitive Guide
image::kafka_cluster.png[{image-60-width}]

== Kafka Message

image::message.jpg[{image-20-width}]

* Номер партиции
* Ключ
* Значение

== Compacted topics
.Источник: Kafka Documentation
image::log_compaction.png[{image-60-width}]

== Наш план

[cols="20a,60a,20a"]
|===
.^|image::kafka.jpg[]
.^|
1. *Конфигурация приложения. Простые (stateless) трансформации*
2. Трансформации с использованием локального состояния
3. Дуализм «поток—таблица» и табличные join-ы
4. Время и оконные операции
.^|image::kafka.jpg[]
|===

[transition="fade-out, slide-in"]
== Kafka Streams API: общая структура KStreams-приложения

[source,java,highlight='1-2']
----
StreamsConfig config = ...;
//Здесь устанавливаем всякие опции

Topology topology = new StreamsBuilder()
//Здесь строим топологию
....build();
----

[transition="fade-in, fade-out"]
== Kafka Streams API: общая структура KStreams-приложения
Топология -- конвейер обработчиков:

[graphviz,"topology-sample.png"]
----
digraph G {

graph [ dpi = 140 ];
rankdir="LR";
node [shape="circle" fontsize=14; fixedsize="true"; width="1.3" ];


a[label="source"];
b[label="source"];
c[label="branch /\nsplit"];

d[label="process"];
e[label="join /\nmerge"];
f[label="sink"];
g[label="sink"];
{rank = same; a; b;}
a->c;
b->e;
c->e;
c->d;
d->f;
e->g;

}
----


[transition="fade-in, slide-out"]
== Kafka Streams API: общая структура KStreams-приложения

[source,java]
----
StreamsConfig config = ...;
//Здесь устанавливаем всякие опции

Topology topology = new StreamsBuilder()
//Здесь строим топологию
....build(); 


//Это за нас делает SPRING-KAFKA
KafkaStreams streams = new KafkaStreams(topology, config); 
streams.start(); 
...
streams.close();

----



== В Спринге достаточно определить две вещи

* `@Bean KafkaStreamsConfiguration`
* `@Bean Topology`

[.fragment]
[.custom-style]
[cols="30a,70a"]
|===
.^|image::borisov.png[]
.<|И не забудьте про `@EnableKafkaStreams`
|===

== Легенда

[cols="30a,70a"]
|===
.^|image::betting.jpg[]
.^|
* Идут футбольные матчи (меняется счёт)
* Делаются ставки: H, D, A.
* Поток ставок, ключ: `Cyprus-Belgium:A`
* Поток ставок, значение:
[source,java]
----
class Bet {
  String bettor;   //John Doe
  String match;    //Cyprus-Belgium
  Outcome outcome; //A (or H or D)
  long amount;     //100
  double odds;     //1.7
  long timestamp;  //1554215083998
}
----
|===


== @Bean KafkaConfiguration 

[source,java]
----
//ВАЖНО!
@Bean(name = 
    KafkaStreamsDefaultConfiguration
                .DEFAULT_STREAMS_CONFIG_BEAN_NAME)
public KafkaStreamsConfiguration getStreamsConfig() {
    Map<String, Object> props = new HashMap<>();
    //ВАЖНО!
    props.put(StreamsConfig.APPLICATION_ID_CONFIG,
        "stateless-demo-app");
    //ВАЖНО!
    props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 4);
    props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
    ...
    KafkaStreamsConfiguration streamsConfig = 
            new KafkaStreamsConfiguration(props);
    return streamsConfig;
}
----

== @Bean NewTopic

[source,java]
----
@Bean
NewTopic getFilteredTopic() {
    Map<String, String> props = new HashMap<>();
    props.put(
      TopicConfig.CLEANUP_POLICY_CONFIG,
      TopicConfig.CLEANUP_POLICY_COMPACT);
    return new NewTopic("mytopic", 10, (short) 1).configs(props);
}
----


== @Bean Topology
[graphviz, "yelling-topology.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="1.1"];

Source -> MapVal -> Sink

}
-----

[source,java]
----
@Bean
public Topology createTopology(StreamsBuilder streamsBuilder) {
    KStream<String, Bet> input = streamsBuilder.stream(...);
    KStream<String, Long> gain
            = input.mapValues(v -> Math.round(v.getAmount() * v.getOdds()));
    gain.to(GAIN_TOPIC, Produced.with(Serdes.String(),
                new JsonSerde<>(Long.class)));
    return streamsBuilder.build();
}
----


== TopologyTestDriver: создание

[source,java]
----
KafkaStreamsConfiguration config = new KafkaConfiguration()
                                        .getStreamsConfig();
StreamsBuilder sb = new StreamsBuilder();
Topology topology = new TopologyConfiguration().createTopology(sb);
TopologyTestDriver topologyTestDriver = 
        new TopologyTestDriver(topology, 
                               config.asProperties());
----

== TopologyTestDriver: использование

[source,java]
----
Bet bet = Bet.builder()
            .bettor("John Doe")
            .match("Germany-Belgium")
            .outcome(Outcome.H)
            .amount(100)
            .odds(1.7).build();

topologyTestDriver.pipeInput(
    betFactory.create(BET_TOPIC, bet.key(), bet));
----

== TopologyTestDriver: использование

[source,java]
----
ProducerRecord<String, Long> record =
   topologyTestDriver.readOutput(
        GAIN_TOPIC, 
        new StringDeserializer(),
        new JsonDeserializer<>(Long.class)
    );

assertEquals(bet.key(), record.key());
assertEquals(170L, record.value().longValue());
----

== Если что-то пошло не так...

* `default.deserialization.exception.handler` -- не смогли десериализовать
* `default.production.exception.handler` -- брокер отверг сообщение (например, оно слишком велико)

image::failure.jpg[{image-50-width}]

== Если всё совсем развалилось

[source,java]
----
streams.setUncaughtExceptionHandler(
  (Thread thread, Throwable throwable) -> {
    . . .
   });
----

image::uncaughtexception.jpg[{image-100-width}]

[.fragment]
В Спринге всё сложнее (см. код)

== Состояния приложения KafkaStreams

[graphviz, "kstreamsstates.png"]
-----
digraph G {
  graph [ dpi = 150 ]; 
  Created -> Running;
  Running -> Rebalancing;
  Rebalancing -> Running;
  Rebalancing -> PendingShutdown;
  PendingShutdown -> NotRunning;
  Created -> PendingShutdown; 
  Running -> PendingShutdown; 
  Running -> Error;
  Rebalancing -> Error;
  Error -> PendingShutdown; 
  {rank = same; Created; Running;}
  {rank = same; Rebalancing; Error;}
  {rank = same; PendingShutdown; NotRunning;}
}
-----

== Что ещё нужно знать про stateless-трансформации?

[transition="fade-out, slide-in"]
== Простое ветвление стримов
Java-стримы так не могут:
[source,java]
----
KStream<..> foo = ...
KStream<..> bar = foo.mapValues(…).map... to...
Kstream<..> baz = foo.filter(…).map... forEach...
----
[graphviz, "simplebranch.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="0.5"; label=""];
Start, BF, CF, DF [style="invis"]
Start -> A
A -> B -> BF
A -> C -> CF
}
-----

[transition="fade-in, fade-out"]
== Ветвление стримов по условию

Не используйте `KStream.branch`, используйте `KafkaStreamsBrancher`!
[source,java]
----
new KafkaStreamsBrancher<String, String>()
   .branch((key, value) -> value.contains("A"), ks -> ks.to("A"))
   .branch((key, value) -> value.contains("B"), ks -> ks.to("B"))
   .defaultBranch(ks -> ks.to("C"))
   .onTopOf(builder.stream("source"))
   .map(...)
----
[graphviz, "switchbranch.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="0.5"; label=""];
Start, BF, CF, DF [style="invis"]
Branch [shape="diamond", label="?"]
Start -> A -> Branch
Branch -> B -> BF
Branch -> C -> CF
}
-----

[transition="fade-in, slide-out"]
== Простое слияние
[source,java]
----
KStream<String, Integer> foo = ... 
KStream<String, Integer> bar = ...
KStream<String, Integer> merge = foo.merge(bar);
----
[graphviz, "merge.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="0.5"; label=""];
Finish, BF, CF, DF [style="invis"]
BF -> A
CF -> B 
A -> C -> Finish
B -> C 
}
-----

== Наш план
[cols="20a,60a,20a"]
|===
.^|image::kafka.jpg[]
.^|
1. [line-through]#Конфигурация приложения. Простые (stateless) трансформации#
2. *Трансформации с использованием локального состояния*
3. Дуализм «поток—таблица» и табличные join-ы
4. Время и оконные операции
.^|image::kafka.jpg[]
|===

== Локальное состояние

Facebook's RocksDB -- что это и зачем?

[.custom-style]
[cols="25a,75a"]
|===
.^|image::rocksdb.png[]
.^|
* Embedded key/value storage
* LSM Tree (Log-Structured Merge-Tree)
* High-performant (data locality)
* Persistent, optimized for SSD
|===

== RocksDB похож на `TreeMap<K,V>`

* Сохранение K,V в бинарном формате
* Лексикографическая сортировка
* Iterator (snapshot view)
* Удаление диапазона (deleteRange)

== Пишем “Bet Totalling App”

Какова сумма выплат по сделанным ставкам, если сыграет исход?

[graphviz, "counting-topology.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Store [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.5"]
Source -> MapVal -> Sum -> Sink
Sum -> Store [dir=both; label=" \n "]
{rank = same; Store; Sum;}
}
-----

== @Bean Topology

[source,java]
----
KStream<String, Bet> input = streamsBuilder.
    stream(BET_TOPIC, Consumed.with(Serdes.String(),
                      new JsonSerde<>(Bet.class)));

KStream<String, Long> counted =
    new TotallingTransformer()
        .transformStream(streamsBuilder, input);
----

== Суммирование ставок
[source,java]
----
@Override
public KeyValue<String, Long> transform(String key, Bet value,
                    KeyValueStore<String, Long> stateStore) {
    long current = Optional
        .ofNullable(stateStore.get(key))
        .orElse(0L);
    current += value.getAmount();
    stateStore.put(key, current);
    return KeyValue.pair(key, current);
}
----

== StateStore доступен в тестах
[source,java]
----
@Test
void testTopology() {
    topologyTestDriver.pipeInput(...);
    topologyTestDriver.pipeInput(...);

    KeyValueStore<String, Long> store =
        topologyTestDriver
        .getKeyValueStore(TotallingTransformer.STORE_NAME);
    
    assertEquals(..., store.get(...));
    assertEquals(..., store.get(...));
}
----


== Демо: Ребалансировка / репликация

* Ребалансировка / репликация партиций state при запуске / выключении обработчиков.

== Подробнее о ребалансировке

[cols="30a,70a"]
|===
.^|image::matthias.jpg[]
.^|
*Matthias J. Sax* https://www.confluent.io/kafka-summit-lon19/everything-you-wanted-to-know-kafka-afraid[Everything You Always Wanted to Know About Kafka’s Rebalance Protocol but Were Afraid to Ask (Kafka Summit London, 2019)]
|===

== Сохранение локального состояния в{nbsp}топик

[source,code]
----
$kafka-topics --zookeeper localhost --describe

Topic:bet-totalling-demo-app-totalling-store-changelog
PartitionCount:10       
ReplicationFactor:1 
Configs:cleanup.policy=compact
----

[.fragment]
[graphviz, "counting-topology-changelog.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Store [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.5"]
Source -> MapVal -> Sum -> Sink
Sum -> Store [dir=both; label=" \n "]
{rank = same; Store; Sum;}
Store -> Changelog[style="dashed"]
Changelog[shape="box"; style="dashed"; width="1.5"]
}
-----

[transition="fade-out, slide-in"]

== Партиционирование и local state
[graphviz, "local-partitioning-oneworker.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {

     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source"];
          S2 [shape=plaintext label = "Local store"];
          S3 [shape=plaintext label = "Changelog"];
          S1->S2->S3 [style="invis"]
      }

    subgraph cluster_p1 {
      label = "Worker 1";
        
        subgraph cluster_pp2{
              label = "Partition 3"
                
              d[label = "D"];
              
              
          }
          
          
        d->ls1;
        p3[shape="plaintext" label = "Partition 3"];
        ls1->p3[dir="both"];
          
          subgraph cluster_pp11{
              label = "Partition 2"
          
              b [label = "B"];
              c[label = "C"];
              
          }
 
        subgraph cluster_pp1{
              label = "Partition 1"
              
              
              a [label = "A"];
              
          }
          
        
        ls1[shape="cylinder" label = "RocksDB"]
        a->ls1;
        b->ls1;
        c->ls1;
        
        p1[shape="plaintext" label = "Partition 1"];
        p2[shape="plaintext" label = "Partition 2"];
        ls1->p1[dir="both"];
        ls1->p2[dir="both"];
        
        
    }

    
    
  }
} 
-----

[transition="fade-in, slide-out"]
== Партиционирование и local state
[graphviz, "local-partitioning.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {

     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source"];
          S2 [shape=plaintext label = "Local store"];
          S3 [shape=plaintext label = "Changelog"];
          S1->S2->S3 [style="invis"]
      }

    subgraph cluster_p1 {
      label = "Worker 1";
        
          
          subgraph cluster_pp11{
              label = "Partition 2"
          
              b [label = "B"];
              c[label = "C"];
              
          }
 
        subgraph cluster_pp1{
              label = "Partition 1"
              
              
              a [label = "A"];
              
          }
          
        
        ls1[shape="cylinder" label = "RocksDB"]
        a->ls1;
        b->ls1;
        c->ls1;
        
        p1[shape="plaintext" label = "Partition 1"];
        p2[shape="plaintext" label = "Partition 2"];
        ls1->p1[dir="both"];
        ls1->p2[dir="both"];
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 3"
                
              d[label = "D"];
              
              
          }
          
          
        ls2[shape="cylinder" label = "RocksDB"]
        d->ls2;
        p3[shape="plaintext" label = "Partition 3"];
        ls2->p3[dir="both"];
    }
    
    
  }
} 
-----


== Репартиционирование
[graphviz, "through.png"]
-----
digraph G
{
    graph [ dpi = 150 ]; 
    rankdir="LR";
    node [shape=record, width=.1, height=.1];
    node1 [label="{ | | | | }", fontsize = 18, xlabel= "through(. . .)"];
    
    node [label = " "; shape="circle"; fixedsize="true"; width="1.1"];
    Source -> node1
    node1 -> Sink
    
}
-----

* Явное при помощи +
`through(String topic, Produced<K, V> produced)`
* Неявное при операциях, меняющих ключ + stateful-операциях

[transition="fade-out, slide-in"]
== Дублирующееся неявное репартиционирование
[source,java]
----
KStream source = builder.stream("topic1");
KStream mapped = source.map(...);
KTable counts = mapped.groupByKey().aggregate(...);
KStream sink = mapped.leftJoin(counts, ...);
----

[graphviz, "doublethrough.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="0.8"; label=""];
Start, Finish [style="invis"]
Start -> A
A[label="map"]
A -> throughAgg  [style=dashed]
throughAgg -> Agg  [style=dashed]
A -> throughJoin [style=dashed]
throughJoin -> Join [style=dashed]
Agg[label="Agg"]
Join[label="Join"]
Agg -> Join
Join -> Finish
Store [shape="cylinder"; label="Store";]
Agg -> Store [dir="both"]
throughAgg [shape="record"; label="{ | | | | }"; height = "0.2"]
throughJoin [shape="record"; label="{ | | | | }"; height = "0.2"]
}
-----

[transition="fade-in, slide-out"]
== Избавляемся от дублирующегося репартиционирования

[source,java]
----
KStream source = builder.stream("topic1");
KStream shuffled = source.map(...).through("topic2",..);
KTable counts = shuffled.groupByKey().aggregate(...);
KStream sink = shuffled.leftJoin(counts, ...);
----

[graphviz, "implicitthrough.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="0.8"; label=""];
Start, Finish [style="invis"]
Start -> A
A[label="map"]
A -> throughAgg
throughAgg[xlabel="through"]
throughAgg -> Agg
throughAgg -> Join
Agg[label="Agg"]
Join[label="Join"]
Agg -> Join
Join -> Finish
Store [shape="cylinder"; label="Store";]
Agg -> Store [dir="both"]
throughAgg [shape="record"; label="{ | | | | }"; height = "0.2"]
}
-----

== Ключ лучше лишний раз не трогать

*Key only:* `selectKey`

[cols=2*] 
|===
|*Key and Value*
|*Value Only*

|`map`
|`mapValues`

|`flatMap`
|`flatMapValues`

|`transform`
|`transformValues`

|`flatTransform`
|`flatTransformValues`


|===

== Подробнее про «лишнее» репартиционирование

[cols="30a,70a"]
|===
.^|image::guozhang.jpeg[]
.^|
*Guozhang Wang* https://www.confluent.io/kafka-summit-lon19/performance-analysis-optimizations-kafka-streams-applications[Performance Analysis and Optimizations for Kafka Streams Applications (Kafka Summit London, 2019)]
|===

== Наш план

[cols="20a,60a,20a"]
|===
.^|image::kafka.jpg[]
.^|
1. [line-through]#Конфигурация приложения. Простые (stateless) трансформации#
2. [line-through]#Трансформации с использованием локального состояния#
3. *Дуализм «поток—таблица» и табличные join-ы*
4. Время и оконные операции
.^|image::kafka.jpg[]
|===


[transition="fade-out, slide-in"]
== Таблицы vs стримы

Местонахождение пользователя

.Michael G. Noll. Of Streams and Tables in Kafka and Stream Processing
image::stream-table-animation-latestLocation.gif[{image-100-width}]

[transition="fade-in, fade-out"]
== Таблицы vs стримы

Количество посещенных мест

.Michael G. Noll. Of Streams and Tables in Kafka and Stream Processing
image::stream-table-animation-numVisitedLocations.gif[{image-100-width}]

[transition="fade-in, slide-out"]
== Таблицы vs стримы

Производная и интеграл

.Martin Kleppmann, “Designing Data Intensive Applications”
image::derivative-and-integral.png[{image-100-width}]

== Join

image::derivative.png[{image-40-width}]

[graphviz, "join-storages.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Store1 [shape="cylinder"; label="Local Store 1"; fixedsize="true"; width="1.7"]
Store2 [shape="cylinder"; label="Local Store 2"; fixedsize="true"; width="1.7"]
Source1 -> Join
Source2 -> Join

Join -> Sink
Join -> Store1 [dir=both; label=" \n "]
Join -> Store2 [dir=both; label=" \n "]
Store1 -> Store2 [style=invis]
{rank = same; Store1; Join }
}
-----

== Переписываем totalling app при помощи KTable

[source,java]
----
KTable<String, Long> totals = input.groupByKey().aggregate(
    () -> 0L, 
    (k, v, a) -> a + Math.round(v.getAmount() * v.getOdds()),
    Materialized.with(Serdes.String(), Serdes.Long())
);
----

[source,code]
----
$kafka-topics --zookeeper localhost --describe

Topic: 
table2-demo-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog 
PartitionCount:10
ReplicationFactor:1
Configs:cleanup.policy=compact
----


== Получаем таблицу счетов матчей
[source,java]
----
KStream<String, Score> scores = 
    eventScores.flatMap((k, v) ->
        Stream.of(Outcome.H, Outcome.A).map(o ->
            KeyValue.pair(String.format("%s:%s", k, o), v))
            .collect(Collectors.toList()))
    .mapValues(EventScore::getScore);

KTable<String, Score> tableScores =
    scores.groupByKey(Grouped.with(...).reduce((a, b) -> b);

----
[source,code]
----
$kafka-topics --zookeeper localhost --list

table2-demo-KSTREAM-REDUCE-STATE-STORE-0000000006-repartition
table2-demo-KSTREAM-REDUCE-STATE-STORE-0000000006-changelog
----

== Демо: Объединяем сумму ставок с текущим счётом
[source,java]
----
KTable<String, String> joined = 
    totals.join(tableScores,
            (total, eventScore) -> 
                String.format("(%s)\t%d", eventScore, total));
----


[transition="fade-out, slide-in"]
== Копартиционирование

Join работает

[graphviz, "copart-norm.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "Source 2"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        
          
          subgraph cluster_pp11{
              label = "Partition 2"
          
              b [label = "B"];
              c[label = "C"];
              
          }
          subgraph cluster_pp12{
              label = "Partition 2"
              labelloc ="b"
          
              b1 [label = "B"];
              
              c1[label = "C"];
          }
          
          subgraph cluster_p1{
              label = "Partition 1"
          labelloc = "b"
              
              a1 [label = "A"]
              
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
              
              
              a [label = "A"];
              
          }
          
          a->a1[style="dashed" dir="none"];
          b->b1[style="dashed" dir="none"];
          c->c1[style="dashed" dir="none"];
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 3"
                
              d[label = "D"];
              
              
          }
          subgraph cluster_p2{
              label = "Partition 3"
              labelloc = "b"
              d1[label = "D"];
              
              
          }
          
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

[transition="fade-in, fade-out"]
== Несовпадение количества партиций

Join не работает (Runtime Exception)

[graphviz, "copart-diff.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "Source 2"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        subgraph cluster_p1{
              label = "Partition 1"
              labelloc = "b"
              b1 [label = "B"]
              a1 [label = "A"]
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
          
              
              a [label = "A"];
              
          }
          
          subgraph cluster_pa2{
              label = "Partition 2"
          b [label = "B"];
              c [label = "C" color="red"];
              
          }
          a->a1[style="dashed" dir="none"];
          b->b1[style="dashed" dir="none"];
          
          
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 3"
          
              d[label = "D"];
              
              
          }
          subgraph cluster_pa3{
              label = "Partition 2"
              labelloc = "b"
          
              d1[label = "D"];
              c1[label = "C" color ="red"];
              
          }
          c->c1[ dir="none" color="red"];
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

[transition="fade-in, slide-out"]
== Несовпадение алгоритма партицирования

Join не работает молча!

[graphviz, "copart-diff-algorithm.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "Source 2"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        subgraph cluster_p1{
              label = "Partition 1"
              labelloc = "b"
          
              b1 [label = "B" color="red"]
              a1 [label = "A"]
              
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
          
               c[label = "C" color= "red"];
              a [label = "A"];
              
          }
          
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 2"
          b [label = "B" color="red"];
              d[label = "D"];
             
              
          }
          subgraph cluster_p2{
              label = "Partition 2"
              labelloc = "b"
              d1[label = "D"];
              c1[label = "C" color = "red"];
              
          }
          a->a1[style="dashed" dir="none"];
          b->b1[color="red" dir="none"];
          c->c1[color="red" dir="none"];
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

== GlobalKTable

Реплицируется всюду целиком

[source,java]
----
GlobalKTable<...> global = streamsBuilder.globalTable("global", ...);
----

[graphviz, "globalktable.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "GlobalKTable"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        subgraph cluster_p1{
              label = ""
          
              b1 [label = "B"]
              a1 [label = "A"]
              cc [label = "C"] 
              dd [label = "D"]
              a1->cc[style="invis"];
              b1->dd[style="invis"];
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
          
             
              a [label = "A"];
              b [label = "B"];
          }
          
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 2"
                c[label = "C"];
              
              d[label = "D"];
              
             
              
          }
          subgraph cluster_p2{
              label = ""
              labelloc = "b"
              d1[label = "D"];
              c1[label = "C" ];
              aa[label = "A"];
              bbb[label = "B"];
              c1->aa [style= "invis"];
              d1->bbb [style= "invis"];
              
          }
          a->a1[style="dashed" dir="none"];
          b->b1[style="dashed" dir="none"];
          c->c1[style="dashed" dir="none"];
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

== Операции между стримами и таблицами: сводка
.Источник: https://kafka.apache.org/20/documentation/streams/developer-guide/dsl-api.html#stateful-transformations[Kafka Streams DSL Documentation]
image::streams-stateful_operations.png[{image-50-width}]

[transition="fade-out, slide-in"]
== Виды Join-ов: Table-Table

image::table-table.svg[{image-40-width}]

[transition="fade-in, fade-out"]
== Виды Join-ов: Table-Table

image::table-table1.svg[{image-40-width}]

[transition="fade-in, slide-out"]
== Виды Join-ов: Table-Table

image::table-table2.svg[{image-40-width}]

== Виды Join-ов: Stream-Table

image::stream-table.svg[{image-40-width}]

[transition="fade-in, slide-out"]
== Виды Join-ов: Stream-Stream

image::stream-stream.svg[{image-40-width}]


== Наш план

[cols="20a,60a,20a"]
|===
.^|image::kafka.jpg[]
.^|
1. [line-through]#Конфигурация приложения. Простые (stateless) трансформации#
2. [line-through]#Трансформации с использованием локального состояния#
3. [line-through]#Дуализм «поток—таблица» и табличные join-ы#
4. *Время и оконные операции*
.^|image::kafka.jpg[]
|===


== Сохранение Timestamped-значений в{nbsp}RocksDB

WindowKeySchema.java

[source,java]
----
static Bytes toStoreKeyBinary(byte[] serializedKey,
                              long timestamp,
                              int seqnum) {
    ByteBuffer buf = ByteBuffer.allocate(
                                serializedKey.length
                                + TIMESTAMP_SIZE 
                                + SEQNUM_SIZE);
    buf.put(serializedKey);
    buf.putLong(timestamp);
    buf.putInt(seqnum);
    return Bytes.wrap(buf.array());
}
----

== Быстрое извлечение значений по ключу из диапазона времени

[graphviz, "timestamped-record.png"]
-----
digraph G
{
    graph [ dpi = 150 ]; 
    node [shape=record, fontsize=18];
    node0 [label="..."];
    node1 [label="<f0> key|<f1> timestamp|<f2> seqnum"];
    node2 [label="..."];
    node0 -> node1;
    node0 -> node2;
}
-----

== Демо: Windowed Joins

* «Послегольщик» — игрок, пытающийся протолкнуть правильную ставку в момент смены счёта в матче
* Штамп времени ставки и события смены счёта должны «почти совпадать».

image::livebet.jpg[{image-50-width}]

== Время, вперёд!

[source,java]
----
KStream<String, Bet> bets = streamsBuilder.stream(BET_TOPIC,
    Consumed.with(
            Serdes...)
            .withTimestampExtractor(
                
                (record, previousTimestamp) ->
                    ((Bet) record.value()).getTimestamp()

            ));
----
(Ещё время можно извлечь из WallClock и RecordMetadata.)


== Демо: Windowed Joins
По событию смены счёта понимаем, какая ставка будет «правильной»:
[source,java]
----

Score current = Optional.ofNullable(stateStore.get(key))
                .orElse(new Score());
stateStore.put(key, value.getScore());

Outcome currenOutcome = 
    value.getScore().getHome() > current.getHome() 
    ?
    Outcome.H : Outcome.A;
----

== Демо: Windowed Joins
[source, java]
----
KStream<String, String> join = bets.join(outcomes,
    (bet, sureBet) -> 
    
    String.format("%s %dms before goal", 
                bet.getBettor(),
                sureBet.getTimestamp() - bet.getTimestamp()),
                JoinWindows.of(Duration.ofSeconds(1)).before(Duration.ZERO),
                Joined.with(Serdes....
    ));
----


[transition="fade-out, slide-in"]
== Tumbling window

[source,java]
----
TimeWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(TimeWindows.of(Duration.ofSeconds(20)));
----
.Источник: Kafka Streams in Action
image::tumbling-window.png[{image-70-width}]

[transition="fade-in, fade-out"]
== Tumbling window
[source,java]
----
TimeWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(TimeWindows.of(Duration.ofSeconds(20)));
    
KTable<Windowed<...>, Long> count = windowed.count();

/*
* Windowed<K> interface:
* - K key()
* - Window window()
* -- Instant startTime()
* -- Instant endTime()
*/
----

[transition="fade-in, fade-out"]
== Hopping Window
[source,java]
----
TimeWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(TimeWindows.of(Duration.ofSeconds(20))
                        .advanceBy(Duration.ofSeconds(10)));
----
.Источник: Kafka Streams in Action
image::hopping-window.png[{image-50-width}]

[transition="fade-in, slide-out"]
== Session Window
[source,java]
----
SessionWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(SessionWindows.with(Duration.ofMinutes(5)));
----
image::streams-session-windows-02.png[{image-50-width}]

== Window Retention time vs. Grace Time

image::window-retention.png[]


== Иногда нужны не окна, а Punctuator

[.custom-style]
[cols="30a,70a"]
|===
|image::metronome.jpg[]
|
[source,java]
----
class MyTransformer implements Transformer<...> {
    @Override
    public void init(ProcessorContext context) {
    
        context.schedule(
            Duration.ofSeconds(10),
            PunctuationType.WALL_CLOCK_TIME,
            timestamp->{. . .});
            
    }
----
|===

== Наш план

[cols="20a,60a,20a"]
|===
.^|image::kafka.jpg[]
.^|
1. [line-through]#Конфигурация приложения. Простые (stateless) трансформации#
2. [line-through]#Трансформации с использованием локального состояния#
3. [line-through]#Дуализм «поток—таблица» и табличные join-ы#
4. [line-through]#Время и оконные операции#
.^|image::kafka.jpg[]
|===

*Пора закругляться!*

== Kafka Streams in Action

[.custom-style]
[cols="30a,70a"]
|===
|image::KSIA.jpg[]
|
* **William Bejeck**, + 
“Kafka Streams in Action”, November 2018
* Примеры кода для Kafka 1.x
|===

== Kafka: The Definitive Guide

[.custom-style]
[cols="30a,70a"]
|===
|image::kafka-the-definitive-guide.jpg[]
|
* Gwen Shapira, Neha Narkhede, Todd Palino
* September 2017
|===



== Другие источники

- https://docs.confluent.io/current/streams/developer-guide/index.html[docs.confluent.io: Streams Developer Guide]
- https://www.confluent.io/blog/stream-processing-part-1-tutorial-developing-streaming-applications[Getting Your Feet Wet with Stream Processing (Confluent tutorials)]
- Исходники!
** https://github.com/apache/kafka/
** https://github.com/spring-projects/spring-kafka

== Сообщества, конференции
- Телеграм: Грефневая Кафка
** https://t.me/AwesomeKafka_ru
** https://t.me/proKafka
- Kafka Summit Conference

== Некоторые итоги

[%step]
* Kafka StreamsAPI -- это удобная абстракция над «сырой» Кафкой
* Чтобы начать пользоваться, надо настроить мышление под потоковую обработку
* Технология переживает бурное развитие
** + живой community, есть шанс повлиять на процесс самому 
** - публичные интерфейсы изменяются очень быстро

== На этом всё!

icon:github[size=lg] https://github.com/inponomarev/kstreams-examples[inponomarev/kstreams-examples]

icon:twitter[size=lg] https://twitter.com/inponomarev[@inponomarev]

ponomarev@corchestra.ru

*Спасибо!*
