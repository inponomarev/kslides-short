= Kafka Streams API: Шаг за рамки Hello World (краткая версия)
Иван Пономарёв, КУРС/МФТИ
:revealjs_theme: black
:revealjs_customtheme: white_course.css
:revealjs_transition: none
:revealjs_slideNumber:
:revealjs_history:
:revealjs_progress:
:encoding: UTF-8
:lang: ru
include::_doc_general_attributes.adoc[]
:doctype: article
:toclevels: 3
:imagesdir: images
:source-highlighter: pygments
//:highlightjsdir: highlight
:icons: font
:iconfont-remote!:
:iconfont-name: font-awesome-4.7.0/css/font-awesome
:revealjs_mouseWheel: true
:revealjs_center: false
:revealjs_width: 1600
:revealjs_height: 900


//== Часть 1. Введение
:!figure-caption:

ponomarev@corchestra.ru

icon:twitter[size=lg] @inponomarev

[%notitle]
== Кто я такой

[cols="30a,70a"]
|===
.^|image::me.jpg[]
.^|
* Tech Lead at KURS
* ERP systems & Java background
* Speaker at JPoint, Devoops, Heisenbug, JUG.MSK, PermDevDay, DevopsForum, Стачка etc.
* Текущий проект: Real-time Webscraping
|===

== Зачем нам Kafka?

image::kafka.jpg[{image-30-width}]

== Зачем нам Kafka?

[%step]
* Web-scraping в реальном времени
* 500 запросов/сек (да, это очень мало!)
* Удобные штуки «из коробки»:
** Персистентный, но «подрезаемый» лог
** Microbatching

== Зачем нам Streams API?

[%step]
* Real-time stream processing
* Stream-like API (map / reduce)
* Под капотом:
** Ребалансировка
** Внутреннее состояние обработчиков (репликация)
** Легкое масштабирование


== Когда меня спрашивают, какой стриминговый фреймворк использовать

image::weuseflink.jpg[{image-60-width}]


== Disclaimers

1. Предполагается базовое понимание Кафки

** https://www.youtube.com/watch?v=A_yUaPARv8U[Григорий Кошелев — Когда всё пошло по Кафке (JPoint 2019)]

2. Доклад не о жизни в production!

** https://www.youtube.com/watch?v=wCCR1Tkxc-s[Никита Сальников-Тарновский — Streaming architecture — шаг за рамки примеров кода (devclub.eu 2019.03.26)]

// == Kafka Message
// 
// [cols="30a,70a"]
// |===
// .^|image::message.jpg[]
// .^|
// * Номер партиции
// * Ключ
// * Значение
// |===
// 
// == Compacted topics
// .Источник: Kafka Documentation
// image::log_compaction.png[{image-60-width}]

== Kafka Streams API: общая структура KStreams-приложения

[source,java,highlight='1,4,6']
----
StreamsConfig config = ...;
//Здесь устанавливаем всякие опции

Topology topology = new StreamsBuilder()
//Здесь строим топологию
    ....build();
----

== Kafka Streams API: общая структура KStreams-приложения
Топология -- конвейер обработчиков:

[graphviz,"topology-sample.png"]
----
digraph G {

graph [ dpi = 140 ];
rankdir="LR";
node [shape="circle" fontsize=14; fixedsize="true"; width="1.3" ];


a[label="source"];
b[label="source"];
c[label="branch /\nsplit"];

d[label="process"];
e[label="join /\nmerge"];
f[label="sink"];
g[label="sink"];
{rank = same; a; b;}
a->c;
b->e;
c->e;
c->d;
d->f;
e->g;

}
----

== Kafka Streams API: общая структура KStreams-приложения

[source,java,highlight='9-13']
----
StreamsConfig config = ...;
//Здесь устанавливаем всякие опции

Topology topology = new StreamsBuilder()
//Здесь строим топологию
....build(); 


//Это за нас делает SPRING-KAFKA
KafkaStreams streams = new KafkaStreams(topology, config); 
streams.start(); 
...
streams.close();

----



== В Спринге достаточно

* Определить `@Bean KafkaStreamsConfiguration`
* Определить `@Bean Topology`
* И не забыть добавить `@EnableKafkaStreams`

== Легенда

[cols="30a,70a"]
|===
.^|image::betting.jpg[]
.^|
* Идут футбольные матчи (меняется счёт)
* Делаются ставки: H, D, A.
* Поток ставок, ключ: `Cyprus-Belgium:A`
* Поток ставок, значение:
[source,java]
----
class Bet {
  String bettor;   //John Doe
  String match;    //Cyprus-Belgium
  Outcome outcome; //A (or H or D)
  long amount;     //100
  double odds;     //1.7
  long timestamp;  //1554215083998
}
----
|===


// == @Bean KafkaStreamsConfiguration 
// 
// [source,java,highlight='7-8']
// ----
// @Bean(name = 
//     KafkaStreamsDefaultConfiguration
//                 .DEFAULT_STREAMS_CONFIG_BEAN_NAME)
// public KafkaStreamsConfiguration getStreamsConfig() // {
//     Map<String, Object> props = new HashMap<>();
//     //ВАЖНО!
//     props.put(StreamsConfig.APPLICATION_ID_CONFIG,
//         "stateless-demo-app");
//     //ВАЖНО!
//     props.put(StreamsConfig.NUM_STREAM_THREADS_CONF// IG, 4);
//     props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFI// G,
//                                       // "localhost:9092");
//     ...
//     KafkaStreamsConfiguration streamsConfig = 
//             new KafkaStreamsConfiguration(props);
//     return streamsConfig;
// }
// ----
// 
// == @Bean KafkaStreamsConfiguration 
// 
// [source,java,highlight='10']
// ----
// @Bean(name = 
//     KafkaStreamsDefaultConfiguration
//                 .DEFAULT_STREAMS_CONFIG_BEAN_NAME)
// public KafkaStreamsConfiguration getStreamsConfig() // {
//     Map<String, Object> props = new HashMap<>();
//     //ВАЖНО!
//     props.put(StreamsConfig.APPLICATION_ID_CONFIG,
//         "stateless-demo-app");
//     //ВАЖНО!
//     props.put(StreamsConfig.NUM_STREAM_THREADS_CONF// IG, 4);
//     props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFI// G,
//                                       // "localhost:9092");
//     ...
//     KafkaStreamsConfiguration streamsConfig = 
//             new KafkaStreamsConfiguration(props);
//     return streamsConfig;
// }
// ----

== @Bean Topology
[graphviz, "yelling-topology1.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="1.1"];
Source[style=filled; fillcolor="#ffffcc"];
Source -> MapVal -> Sink

}
-----

[source,java,highlight='3-4']
----
@Bean
public Topology createTopology(StreamsBuilder streamsBuilder) {
  KStream<String, Bet> input = streamsBuilder.stream(
     BET_TOPIC, Consumed.with(Serdes...);
  KStream<String, Long> gain = input.mapValues(
              v -> Math.round(v.getAmount() * v.getOdds()));
  gain.to(GAIN_TOPIC, Produced.with(Serdes.String(),
                new JsonSerde<>(Long.class)));
  return streamsBuilder.build();
}
----


== @Bean Topology
[graphviz, "yelling-topology2.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="1.1"];
MapVal[style=filled; fillcolor="#ffffcc"];

Source -> MapVal -> Sink

}
-----

[source,java,highlight='5-6']
----
@Bean
public Topology createTopology(StreamsBuilder streamsBuilder) {
  KStream<String, Bet> input = streamsBuilder.stream(
     BET_TOPIC, Consumed.with(Serdes...);
  KStream<String, Long> gain = input.mapValues(
              v -> Math.round(v.getAmount() * v.getOdds()));
  gain.to(GAIN_TOPIC, Produced.with(Serdes.String(),
                new JsonSerde<>(Long.class)));
  return streamsBuilder.build();
}
----


== @Bean Topology
[graphviz, "yelling-topology3.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="1.1"];
Sink[style=filled; fillcolor="#ffffcc"];

Source -> MapVal -> Sink

}
-----

[source,java,highlight='7-8']
----
@Bean
public Topology createTopology(StreamsBuilder streamsBuilder) {
  KStream<String, Bet> input = streamsBuilder.stream(
     BET_TOPIC, Consumed.with(Serdes...);
  KStream<String, Long> gain = input.mapValues(
              v -> Math.round(v.getAmount() * v.getOdds()));
  gain.to(GAIN_TOPIC, Produced.with(Serdes.String(),
                new JsonSerde<>(Long.class)));
  return streamsBuilder.build();
}
----

== Как проверить, что оно считает правильно?

`TopologyTestDriver` to the resque!

== TopologyTestDriver: создание

[source,java,highlight='1-2,5-6']
----
KafkaStreamsConfiguration config = new KafkaConfiguration()
                                        .getStreamsConfig();
StreamsBuilder sb = new StreamsBuilder();

Topology topology = 
    new TopologyConfiguration().createTopology(sb);

//Наличие настоящей Кафки не требуется
TopologyTestDriver topologyTestDriver = 
        new TopologyTestDriver(topology, 
                               config.asProperties());
----

== TopologyTestDriver: создание

[source,java,highlight='8-11']
----
KafkaStreamsConfiguration config = new KafkaConfiguration()
                                        .getStreamsConfig();
StreamsBuilder sb = new StreamsBuilder();

Topology topology = 
    new TopologyConfiguration().createTopology(sb);

//Наличие настоящей Кафки не требуется
TopologyTestDriver topologyTestDriver = 
        new TopologyTestDriver(topology, 
                               config.asProperties());
----

== TopologyTestDriver: использование

[source,java,highlight='8']
----
Bet bet = Bet.builder()
            .bettor("John Doe")
            .match("Germany-Belgium")
            .outcome(Outcome.H)
            .amount(100)
            .odds(1.7).build();

topologyTestDriver.pipeInput(
    betFactory.create(BET_TOPIC, bet.key(), bet));
----

== TopologyTestDriver: использование

[source,java,highlight='2']
----
ProducerRecord<String, Long> record =
   topologyTestDriver.readOutput(
        GAIN_TOPIC, 
        new StringDeserializer(),
        new JsonDeserializer<>(Long.class)
    );

assertEquals(bet.key(), record.key());
assertEquals(170L, record.value().longValue());
----

== TopologyTestDriver: использование

[source,java,highlight='8,9']
----
ProducerRecord<String, Long> record =
   topologyTestDriver.readOutput(
        GAIN_TOPIC, 
        new StringDeserializer(),
        new JsonDeserializer<>(Long.class)
    );

assertEquals(bet.key(), record.key());
assertEquals(170L, record.value().longValue());
----

== Как понять, что граф топологии построен правильно?

* Метод `describe()`
[source,java]
System.out.println(topology.describe());
* Kafka Streams Topology Visualizer (https://zz85.github.io/kafka-streams-viz/)

== Визуализация топологии

image::visualizer.png[{image-50-width}]

// == Как обработать ошибки?
// 
// [%step]
// * `default.deserialization.exception.handler` -- не смогли // десериализовать
// * `default.production.exception.handler` -- брокер отверг сообщение // (например, оно слишком велико)
// 
// == Как обработать ошибки?
// 
// * `default.deserialization.exception.handler` -- не смогли // десериализовать
// * `default.production.exception.handler` -- брокер отверг сообщение // (например, оно слишком велико)
// * Если совсем развалилось:
// [source,java]
// ----
// streams.setUncaughtExceptionHandler(
//   (Thread thread, Throwable throwable) -> {
//     . . .
//    });
// ----

// == Что ещё нужно знать про stateless-трансформации?
// 
// == Простое ветвление стримов
// Java-стримы так не могут:
// [source,java]
// ----
// KStream<..> foo = ...
// KStream<..> bar = foo.mapValues(…).map... to...
// Kstream<..> baz = foo.filter(…).map... forEach...
// ----
// [graphviz, "simplebranch.png"]
// -----
// digraph G {
// graph [ dpi = 150 ]; 
// rankdir="LR";
// node [fontsize=16; shape="circle"; // fixedsize="true"; width="0.5"; label=""];
// Start, BF, CF, DF [style="invis"]
// Start -> A
// A -> B -> BF
// A -> C -> CF
// }
// -----
// 
// == Ветвление стримов по условию
// 
// Не используйте `KStream.branch`, используйте // `KafkaStreamsBrancher`!
// [source,java]
// ----
// new KafkaStreamsBrancher<String, String>()
//    .branch((key, value) -> value.contains("A"), ks // -> ks.to("A"))
//    .branch((key, value) -> value.contains("B"), ks // -> ks.to("B"))
//    .defaultBranch(ks -> ks.to("C"))
//    .onTopOf(builder.stream("source"))
//    .map(...)
// ----
// [graphviz, "switchbranch.png"]
// -----
// digraph G {
// graph [ dpi = 150 ]; 
// rankdir="LR";
// node [fontsize=16; shape="circle"; // fixedsize="true"; width="0.5"; label=""];
// Start, BF, CF, DF [style="invis"]
// Branch [shape="diamond", label="?"]
// Start -> A -> Branch
// Branch -> B -> BF
// Branch -> C -> CF
// }
// -----
// 
// == Простое слияние
// [source,java]
// ----
// KStream<String, Integer> foo = ... 
// KStream<String, Integer> bar = ...
// KStream<String, Integer> merge = foo.merge(bar);
// ----
// [graphviz, "merge.png"]
// -----
// digraph G {
// graph [ dpi = 150 ]; 
// rankdir="LR";
// node [fontsize=16; shape="circle"; // fixedsize="true"; width="0.5"; label=""];
// Finish, BF, CF, DF [style="invis"]
// BF -> A
// CF -> B 
// A -> C -> Finish
// B -> C 
// }
// -----

== Локальное состояние

Facebook's RocksDB -- что это и зачем?

[.custom-style]
[cols="25a,75a"]
|===
.^|image::rocksdb.png[{image-80-width}]
.^|
* Embedded key/value storage
* LSM Tree (Log-Structured Merge-Tree)
* High-performant (data locality)
* Persistent, optimized for SSD
|===

== RocksDB похож на `TreeMap<K,V>`

[.custom-style]
[cols="25a,75a"]
|===
.^|image::rocksdb.png[{image-80-width}]
.^|
* Сохранение K,V в бинарном формате
* Лексикографическая сортировка
* Iterator (snapshot view)
* Удаление диапазона (deleteRange)
|===

== Пишем “Bet Totalling App”

Какова сумма выплат по сделанным ставкам, если сыграет исход?

== @Bean Topology

[graphviz, "counting-topology1.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Source[style=filled; fillcolor="#ffffcc"];
Store [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.5"]
Source -> MapVal -> Sum -> Sink
Sum -> Store [dir=both; label=" \n "]
{rank = same; Store; Sum;}
}
-----

[source,java,highlight='2']
----
KStream<String, Bet> input = streamsBuilder.
    stream(BET_TOPIC, Consumed.with(Serdes.String(),
                      new JsonSerde<>(Bet.class)));
----

== @Bean Topology

[graphviz, "counting-topology2.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
MapVal[style=filled; fillcolor="#ffffcc"];
Store [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.5"]
Source -> MapVal -> Sum -> Sink
Sum -> Store [dir=both; label=" \n "]
{rank = same; Store; Sum;}
}
-----

[source,java,highlight='3']
----
KStream<String, Long> gain
    = input.mapValues(
      v -> Math.round(v.getAmount() * v.getOdds()));

//Key: "Germany-Belgium:H"
//Value: 170L
----

== @Bean Topology

[graphviz, "counting-topology3.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Sum[style=filled; fillcolor="#ffffcc"];
Store [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.5";style=filled; fillcolor="#ffffcc"]
Source -> MapVal -> Sum -> Sink
Sum -> Store [dir=both; label=" \n "]
{rank = same; Store; Sum;}
}
-----

[source,java,highlight='3']
----
KStream<String, Long> counted =
    new TotallingTransformer()
            .transformStream(streamsBuilder, gain);
----


== TotallingTransformer
[source,java,highlight='4-6']
----
@Override
public KeyValue<String, Long> transform(String key, Bet value,
                    KeyValueStore<String, Long> stateStore) {
    long current = Optional
        .ofNullable(stateStore.get(key))
        .orElse(0L);
    current += value.getAmount();
    stateStore.put(key, current);
    return KeyValue.pair(key, current);
}
----

== TotallingTransformer
[source,java,highlight='7']
----
@Override
public KeyValue<String, Long> transform(String key, Bet value,
                    KeyValueStore<String, Long> stateStore) {
    long current = Optional
        .ofNullable(stateStore.get(key))
        .orElse(0L);
    current += value.getAmount();
    stateStore.put(key, current);
    return KeyValue.pair(key, current);
}
----

== TotallingTransformer
[source,java,highlight='8']
----
@Override
public KeyValue<String, Long> transform(String key, Bet value,
                    KeyValueStore<String, Long> stateStore) {
    long current = Optional
        .ofNullable(stateStore.get(key))
        .orElse(0L);
    current += value.getAmount();
    stateStore.put(key, current);
    return KeyValue.pair(key, current);
}
----


== StateStore доступен в тестах
[source,java,highlight='8,10,11']
----
@Test
void testTopology() {
    topologyTestDriver.pipeInput(...);
    topologyTestDriver.pipeInput(...);

    KeyValueStore<String, Long> store =
        topologyTestDriver
        .getKeyValueStore(TotallingTransformer.STORE_NAME);
    
    assertEquals(..., store.get(...));
    assertEquals(..., store.get(...));
}
----


== Демо: Ребалансировка / репликация

* Ребалансировка / репликация партиций state при запуске / выключении обработчиков.


== Сохранение локального состояния в{nbsp}топик

[source,code]
----
$kafka-topics --zookeeper localhost --describe

Topic:bet-totalling-demo-app-totalling-store-changelog
PartitionCount:10       
ReplicationFactor:1 
Configs:cleanup.policy=compact
----


== Мы думали, картина такая...
[graphviz, "counting-topology-changelog1.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Store [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.5"]
Source -> MapVal -> Sum -> Sink
Sum -> Store [dir=both; label=" \n "]
{rank = same; Store; Sum;}
Store -> Changelog[style="invis"]
Changelog[shape="box"; style="invis"; width="1.5"; fillcolor="#ffffcc"]
}
-----

== ...но на самом деле она вот какая:
[graphviz, "counting-topology-changelog2.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Store [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.5"]
Source -> MapVal -> Sum -> Sink
Sum -> Store [dir=both; label=" \n "]
{rank = same; Store; Sum;}
Store -> Changelog
Changelog[shape="box"; style="filled"; width="1.5"; fillcolor="#ffffcc"]
}
-----

== Партиционирование и local state
[graphviz, "local-partitioning-oneworker.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {

     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source"];
          S2 [shape=plaintext label = "Local store"];
          S3 [shape=plaintext label = "Changelog"];
          S1->S2->S3 [style="invis"]
      }

    subgraph cluster_p1 {
      label = "Worker 1";
        
        subgraph cluster_pp2{
              label = "Partition 3"
                
              d[label = "D"];
              
              
          }
          
          
        d->ls1;
        
        ls1->p3[dir="both"];
          
          subgraph cluster_pp11{
              label = "Partition 2"
          
              b [label = "B"];
              c[label = "C"];
              
          }
 
        subgraph cluster_pp1{
              label = "Partition 1"
              
              
              a [label = "A"];
              
          }
          
        
        ls1[shape="cylinder" label = "RocksDB"]
        a->ls1;
        b->ls1;
        c->ls1;
        
        p1[shape="plaintext"; style="filled"; fillcolor="#ffffcc"; label = "Partition 2"];
        p2[shape="plaintext"; style="filled"; fillcolor="#ffffcc"; label = "Partition 3"];
        p3[shape="plaintext"; style="filled"; fillcolor="#ffffcc"; label = "Partition 1"];
        ls1->p1[dir="both"];
        ls1->p2[dir="both"];
        
        
    }

    
    
  }
} 
-----

== Партиционирование и local state
[graphviz, "local-partitioning.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {

     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source"];
          S2 [shape=plaintext label = "Local store"];
          S3 [shape=plaintext label = "Changelog"];
          S1->S2->S3 [style="invis"]
      }

    subgraph cluster_p1 {
      label = "Worker 1";
        
          
          subgraph cluster_pp11{
              label = "Partition 2"
          
              b [label = "B"];
              c[label = "C"];
              
          }
 
        subgraph cluster_pp1{
              label = "Partition 1"
              
              
              a [label = "A"];
              
          }
          
        
        ls1[shape="cylinder" label = "RocksDB"]
        a->ls1;
        b->ls1;
        c->ls1;
        
        p1[shape="plaintext"; style="filled"; fillcolor="#ffffcc"; label = "Partition 1"];
        p2[shape="plaintext"; style="filled"; fillcolor="#ffffcc"; label = "Partition 2"];
        ls1->p1[dir="both"];
        ls1->p2[dir="both"];
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 3"
                
              d[label = "D"];
              
              
          }
          
          
        ls2[shape="cylinder" label = "RocksDB"]
        d->ls2;
        p3[shape="plaintext"; style="filled"; fillcolor="#ffffcc"; label = "Partition 3"];
        ls2->p3[dir="both"];
    }
    
    
  }
} 
-----

// == Подробнее о ребалансировке
// 
// [cols="30a,70a"]
// |===
// .^|image::matthias.jpg[]
// .^|
// *Matthias J. Sax* // https://www.confluent.io/kafka-summit-lon19/everyth// ing-you-wanted-to-know-kafka-afraid[Everything You // Always Wanted to Know About Kafka’s Rebalance // Protocol but Were Afraid to Ask (Kafka Summit // London, 2019)]
// |===


== Репартиционирование
[graphviz, "through.png"]
-----
digraph G
{
    graph [ dpi = 150 ]; 
    rankdir="LR";
    node [shape=record, width=.1, height=.1];
    node1 [label="{ | | | | }", fontsize = 18, xlabel= "through(. . .)"];
    
    node [label = " "; shape="circle"; fixedsize="true"; width="1.1"];
    Source -> node1
    node1 -> Sink
    
}
-----

* Неявное при операциях, меняющих ключ + stateful-операциях
* Явное при помощи +
`through(String topic, Produced<K, V> produced)`


== Дублирующееся неявное репартиционирование
[source,java]
----
KStream source = builder.stream("topic1");
KStream mapped = source.map(...);
KTable counts = mapped.groupByKey().aggregate(...);
KStream sink = mapped.leftJoin(counts, ...);
----

[graphviz, "doublethrough.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="0.8"; label=""];
Start, Finish [style="invis"]
Start -> A
A[label="map"]
A -> throughAgg  [style=dashed]
throughAgg -> Agg  [style=dashed]
A -> throughJoin [style=dashed]
throughJoin -> Join [style=dashed]
Agg[label="Agg"]
Join[label="Join"]
Agg -> Join
Join -> Finish
Store [shape="cylinder"; label="Store";]
Agg -> Store [dir="both"]
throughAgg [shape="record"; label="{ | | | | }"; height = "0.2"]
throughJoin [shape="record"; label="{ | | | | }"; height = "0.2"]
}
-----

== Избавляемся от дублирующегося репартиционирования

[source,java]
----
KStream source = builder.stream("topic1");
KStream shuffled = source.map(...).through("topic2",..);
KTable counts = shuffled.groupByKey().aggregate(...);
KStream sink = shuffled.leftJoin(counts, ...);
----

[graphviz, "implicitthrough.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="0.8"; label=""];
Start, Finish [style="invis"]
Start -> A
A[label="map"]
A -> throughAgg
throughAgg[xlabel="through"]
throughAgg -> Agg
throughAgg -> Join
Agg[label="Agg"]
Join[label="Join"]
Agg -> Join
Join -> Finish
Store [shape="cylinder"; label="Store";]
Agg -> Store [dir="both"]
throughAgg [shape="record"; label="{ | | | | }"; height = "0.2"]
}
-----

// == Ключ лучше лишний раз не трогать
// 
// *Key only:* `selectKey`
// 
// [cols=2*] 
// |===
// |*Key and Value*
// |*Value Only*
// 
// |`map`
// |`mapValues`
// 
// |`flatMap`
// |`flatMapValues`
// 
// |`transform`
// |`transformValues`
// 
// |`flatTransform`
// |`flatTransformValues`
// 
// 
// |===
// 
// == Подробнее про «лишнее» репартиционирование
// 
// [cols="30a,70a"]
// |===
// .^|image::guozhang.jpeg[]
// .^|
// *Guozhang Wang* // https://www.confluent.io/kafka-summit-lon19/perform// ance-analysis-optimizations-kafka-streams-applicati// ons[Performance Analysis and Optimizations for // Kafka Streams Applications (Kafka Summit London, // 2019)]
// |===


// == Таблицы vs стримы
// 
// Местонахождение пользователя
// 
// .Michael G. Noll. Of Streams and Tables in Kafka and Stream Processing
// image::stream-table-animation-latestLocation.gif[{image-100-width}]
// 
// 
// == Таблицы vs стримы
// 
// Количество посещенных мест
// 
// .Michael G. Noll. Of Streams and Tables in Kafka and Stream Processing
// image::stream-table-animation-numVisitedLocations.gif[{image-100-width}// ]


== Таблицы vs стримы

Производная и интеграл

.Martin Kleppmann, “Designing Data Intensive Applications”
image::derivative-and-integral.png[{image-100-width}]

== Переписываем totalling app при помощи KTable

[source,java,highlight='3']
----
KTable<String, Long> totals = input.groupByKey().aggregate(
    () -> 0L, 
    (k, v, a) -> a + Math.round(v.getAmount() * v.getOdds()),
    Materialized.with(Serdes.String(), Serdes.Long())
);
----

== Переписываем totalling app при помощи KTable

[source,java,highlight='4']
----
KTable<String, Long> totals = input.groupByKey().aggregate(
    () -> 0L, 
    (k, v, a) -> a + Math.round(v.getAmount() * v.getOdds()),
    Materialized.with(Serdes.String(), Serdes.Long())
);
----

[source,code]
----
$kafka-topics --zookeeper localhost --describe

Topic: 
table2-demo-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog 
PartitionCount:10
ReplicationFactor:1
Configs:cleanup.policy=compact
----


== Виды Join-ов: Table-Table

image::table-table.svg[{image-40-width}]

== Виды Join-ов: Table-Table

image::table-table1.svg[{image-40-width}]

== Виды Join-ов: Table-Table

image::table-table2.svg[{image-40-width}]

// == Table-table Join
// 
// image::derivative.png[{image-40-width}]
// 
// [graphviz, "join-storages.png"]
// -----
// digraph G {
// graph [ dpi = 150 ]; 
// rankdir="LR";
// node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
// Store1 [shape="cylinder"; label="Local Store 1"; fixedsize="true"; // width="1.7"]
// Store2 [shape="cylinder"; label="Local Store 2"; fixedsize="true"; // width="1.7"]
// Source1 -> Join
// Source2 -> Join
// 
// Join -> Sink
// Join -> Store1 [dir=both; label=" \n "]
// Join -> Store2 [dir=both; label=" \n "]
// Store1 -> Store2 [style=invis]
// {rank = same; Store1; Join }
// }
// -----

== Виды Join-ов: Stream-Table

image::stream-table.svg[{image-40-width}]

== Виды Join-ов: оконный Stream-Stream

image::stream-stream.svg[{image-40-width}]



== Получаем таблицу счетов матчей

[source,java,highlight='7-12']
----
KStream<String, EventScore> eventScores =
    streamsBuilder.stream(EVENT_SCORE_TOPIC,
                Consumed.with(Serdes.String(), 
                new JsonSerde<>(EventScore.class)
                ));
        /*  ключ не пригоден для join-а с суммой ставок
            Key: Germany-Belgium
            Value: EventScore {
                     event     = Germany-Belgium;
                     score     = 1:0;
                     timestamp = 554215083998;
             }
         */
----

== Получаем таблицу счетов матчей

[source,java,highlight='2,8-9,11-12']
----
KStream<String, Score> scores = eventScores
    .flatMap((k, v) ->
        Stream.of(Outcome.H, Outcome.A).map(o ->
            KeyValue.pair(
                    String.format("%s:%s", k, o), v))
            .collect(Collectors.toList()))
    /*
        Key: Germany-Belgium:H
        Value: EventScore
        
        Key: Germany-Belgium:A
        Value: EventScore
    */
    .mapValues(EventScore::getScore);

----

== Превращаем поток в таблицу
[source,java,highlight='5']
----
KTable<String, Score> tableScores =
    scores.groupByKey(
        Grouped.with(Serdes.String(), 
                     new JsonSerde<>(Score.class)))
    .reduce((a, b) -> b);
----

== Получаем таблицу счетов матчей

[source,java,highlight='6-7']
----
KTable<String, String> joined = 
    totals.join(tableScores,
            (total, eventScore) -> 
                String.format("(%s)\t%d", eventScore, total));
                
/*Key: Germany-Belgium:H
  Value: (1:0) 171340*/
----

== Демо: join() и leftJoin() 

== Копартиционирование

Join работает

[graphviz, "copart-norm.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "Source 2"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        
          
          subgraph cluster_pp11{
              label = "Partition 2"
          
              b [label = "B"];
              c[label = "C"];
              
          }
          subgraph cluster_pp12{
              label = "Partition 2"
              labelloc ="b"
          
              b1 [label = "B"];
              
              c1[label = "C"];
          }
          
          subgraph cluster_p1{
              label = "Partition 1"
          labelloc = "b"
              
              a1 [label = "A"]
              
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
              
              
              a [label = "A"];
              
          }
          
          a->a1[style="dashed" dir="none"];
          b->b1[style="dashed" dir="none"];
          c->c1[style="dashed" dir="none"];
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 3"
                
              d[label = "D"];
              
              
          }
          subgraph cluster_p2{
              label = "Partition 3"
              labelloc = "b"
              d1[label = "D"];
              
              
          }
          
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

== Несовпадение количества партиций

Join не работает (Runtime Exception)

[graphviz, "copart-diff.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "Source 2"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        subgraph cluster_p1{
              label = "Partition 1"
              labelloc = "b"
              b1 [label = "B"]
              a1 [label = "A"]
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
          
              
              a [label = "A"];
              
          }
          
          subgraph cluster_pa2{
              label = "Partition 2"
          b [label = "B"];
              c [label = "C" color="red"];
              
          }
          a->a1[style="dashed" dir="none"];
          b->b1[style="dashed" dir="none"];
          
          
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 3"
          
              d[label = "D"];
              
              
          }
          subgraph cluster_pa3{
              label = "Partition 2"
              labelloc = "b"
          
              d1[label = "D"];
              c1[label = "C" color ="red"];
              
          }
          c->c1[ dir="none" color="red"];
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

== Несовпадение алгоритма партицирования

Join не работает молча!

[graphviz, "copart-diff-algorithm.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "Source 2"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        subgraph cluster_p1{
              label = "Partition 1"
              labelloc = "b"
          
              b1 [label = "B" color="red"]
              a1 [label = "A"]
              
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
          
               c[label = "C" color= "red"];
              a [label = "A"];
              
          }
          
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 2"
          b [label = "B" color="red"];
              d[label = "D"];
             
              
          }
          subgraph cluster_p2{
              label = "Partition 2"
              labelloc = "b"
              d1[label = "D"];
              c1[label = "C" color = "red"];
              
          }
          a->a1[style="dashed" dir="none"];
          b->b1[color="red" dir="none"];
          c->c1[color="red" dir="none"];
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

== GlobalKTable

Реплицируется всюду целиком

[source,java]
----
GlobalKTable<...> global = streamsBuilder.globalTable("global", ...);
----

[graphviz, "globalktable.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "GlobalKTable"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        subgraph cluster_p1{
              label = ""
          
              b1 [label = "B"]
              a1 [label = "A"]
              cc [label = "C"] 
              dd [label = "D"]
              a1->cc[style="invis"];
              b1->dd[style="invis"];
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
          
             
              a [label = "A"];
              b [label = "B"];
          }
          
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 2"
                c[label = "C"];
              
              d[label = "D"];
              
             
              
          }
          subgraph cluster_p2{
              label = ""
              labelloc = "b"
              d1[label = "D"];
              c1[label = "C" ];
              aa[label = "A"];
              bbb[label = "B"];
              c1->aa [style= "invis"];
              d1->bbb [style= "invis"];
              
          }
          a->a1[style="dashed" dir="none"];
          b->b1[style="dashed" dir="none"];
          c->c1[style="dashed" dir="none"];
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

// == Операции между стримами и таблицами: сводка
// .Источник: https://kafka.apache.org/20/documentatio// n/streams/developer-guide/dsl-api.html#stateful-tra// nsformations[Kafka Streams DSL Documentation]
// image::streams-stateful_operations.png[{image-50-wi// dth}]
// 



== Сохранение Timestamped-значений в{nbsp}RocksDB

WindowKeySchema.java

[source,java,highlight='8-10']
----
static Bytes toStoreKeyBinary(byte[] serializedKey,
                              long timestamp,
                              int seqnum) {
    ByteBuffer buf = ByteBuffer.allocate(
                                serializedKey.length
                                + TIMESTAMP_SIZE 
                                + SEQNUM_SIZE);
    buf.put(serializedKey);
    buf.putLong(timestamp);
    buf.putInt(seqnum);
    return Bytes.wrap(buf.array());
}
----

== Быстрое извлечение значений по ключу из диапазона времени

[graphviz, "timestamped-record.png"]
-----
digraph G
{
    graph [ dpi = 150 ]; 
    node [shape=record, fontsize=18];
    node0 [label="..."];
    node1 [label="<f0> key|<f1> timestamp|<f2> seqnum"];
    node2 [label="..."];
    node0 -> node1;
    node0 -> node2;
}
-----

== Демо: Windowed Joins

* «Послегольщик» — игрок, пытающийся протолкнуть правильную ставку в момент смены счёта в матче
* Штамп времени ставки и события смены счёта должны «почти совпадать».

image::livebet.jpg[{image-50-width}]

== Время, вперёд!

[source,java,highlight='4-6']
----
KStream<String, Bet> bets = streamsBuilder.stream(BET_TOPIC,
    Consumed.with(
            Serdes...)
            .withTimestampExtractor(
                (record, previousTimestamp) ->
                    ((Bet) record.value()).getTimestamp()
            ));
----
(Ещё время можно извлечь из WallClock и RecordMetadata.)


== Из событий смены счёта фомируем поток "surebets"
[source,java,highlight='4-5']
----
@Override
public KeyValue<String, Bet> transform (String key, 
  EventScore value, KeyValueStore<..> stateStore) {
  Score current = Optional.ofNullable(stateStore.get(key))
                .orElse(new Score());
  stateStore.put(key, value.getScore());
  Outcome currenOutcome = 
    value.getScore().getHome() > current.getHome() 
    ?
    Outcome.H : Outcome.A;
  Bet bestBet = new Bet(null, value.getEvent(), 
               currenOutcome, 0, 1, value.getTimestamp());
  return KeyValue.pair(
    String.format("%s:%s", key, currenOutcome)
    , bestBet);
}
----

== Из событий смены счёта фомируем поток "surebets"
[source,java,highlight='6']
----
@Override
public KeyValue<String, Bet> transform (String key, 
  EventScore value, KeyValueStore<..> stateStore) {
  Score current = Optional.ofNullable(stateStore.get(key))
                .orElse(new Score());
  stateStore.put(key, value.getScore());
  Outcome currenOutcome = 
    value.getScore().getHome() > current.getHome() 
    ?
    Outcome.H : Outcome.A;
  Bet bestBet = new Bet(null, value.getEvent(), 
               currenOutcome, 0, 1, value.getTimestamp());
  return KeyValue.pair(
    String.format("%s:%s", key, currenOutcome)
    , bestBet);
}
----

== Из событий смены счёта фомируем поток "surebets"
[source,java,highlight='7-10']
----
@Override
public KeyValue<String, Bet> transform (String key, 
  EventScore value, KeyValueStore<..> stateStore) {
  Score current = Optional.ofNullable(stateStore.get(key))
                .orElse(new Score());
  stateStore.put(key, value.getScore());
  Outcome currenOutcome = 
    value.getScore().getHome() > current.getHome() 
    ?
    Outcome.H : Outcome.A;
  Bet bestBet = new Bet(null, value.getEvent(), 
               currenOutcome, 0, 1, value.getTimestamp());
  return KeyValue.pair(
    String.format("%s:%s", key, currenOutcome)
    , bestBet);
}
----


== Из событий смены счёта фомируем поток "surebets"
[source,java,highlight='14']
----
@Override
public KeyValue<String, Bet> transform (String key, 
  EventScore value, KeyValueStore<..> stateStore) {
  Score current = Optional.ofNullable(stateStore.get(key))
                .orElse(new Score());
  stateStore.put(key, value.getScore());
  Outcome currenOutcome = 
    value.getScore().getHome() > current.getHome() 
    ?
    Outcome.H : Outcome.A;
  Bet bestBet = new Bet(null, value.getEvent(), 
               currenOutcome, 0, 1, value.getTimestamp());
  return KeyValue.pair(
    String.format("%s:%s", key, currenOutcome)
    , bestBet);
}
----


== Демо: Windowed Joins
[source, java,highlight='1,8']
----
KStream<String, String> join = bets.join(winningBets,
    (bet, winningBet) ->
            String.format("%s bet %s=%s %d",
                    bet.getBettor(),
                    bet.getOutcome(),
                    winningBet.getOutcome(),
                    winningBet.getTimestamp() - bet.getTimestamp()),
    JoinWindows.of(Duration.ofSeconds(1)).before(Duration.ZERO),
    Joined.with(Serdes.String(),
            new JsonSerde<>(Bet.class),
            new JsonSerde<>(Bet.class)
    ));
----

== Без тестов не разберёшься!

[source,java,highlight='9,13']
----
@Test
public void nearBetsFound() {
  long current = System.currentTimeMillis();
  putScore(new EventScore(
    "Turkey-Moldova", new Score().goalHome(), current));
  putBet(new Bet(
    "alice", "Turkey-Moldova", Outcome.A, 1, 1.5, current - 100));
  putBet(new Bet(
    "bob", "Turkey-Moldova", Outcome.H, 1, 1.5, current - 100));
  putBet(new Bet(
    "bob", "Turkey-Moldova", Outcome.H, 1, 1.5, current - 5000));
  assertEquals(
    Arrays.asList("Turkey-Moldova:H-bob bet H=H 100"), output);
}
----

== Tumbling window

[source,java]
----
TimeWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(TimeWindows.of(Duration.ofSeconds(20)));
----
.Источник: Kafka Streams in Action
image::tumbling-window.png[{image-70-width}]

== Tumbling window
[source,java]
----
TimeWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(TimeWindows.of(Duration.ofSeconds(20)));
    
KTable<Windowed<...>, Long> count = windowed.count();

/*
* Windowed<K> interface:
* - K key()
* - Window window()
* -- Instant startTime()
* -- Instant endTime()
*/
----

== Hopping Window
[source,java]
----
TimeWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(TimeWindows.of(Duration.ofSeconds(20))
                        .advanceBy(Duration.ofSeconds(10)));
----
.Источник: Kafka Streams in Action
image::hopping-window.png[{image-50-width}]

== Session Window
[source,java]
----
SessionWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(SessionWindows.with(Duration.ofMinutes(5)));
----
image::streams-session-windows-02.png[{image-50-width}]


== Иногда нужны не окна, а Punctuator

[.custom-style]
[cols="30a,70a"]
|===
|image::metronome.jpg[]
|
[source,java]
----
class MyTransformer implements Transformer<...> {
    @Override
    public void init(ProcessorContext context) {
    
        context.schedule(
            Duration.ofSeconds(10),
            PunctuationType.WALL_CLOCK_TIME,
            timestamp->{. . .});
            
    }
----
|===

== Kafka Streams in Action

[.custom-style]
[cols="30a,70a"]
|===
|image::KSIA.jpg[]
|
* **William Bejeck**, + 
“Kafka Streams in Action”, November 2018
* Примеры кода для Kafka 1.x
|===


== Другие источники

- https://docs.confluent.io/current/streams/developer-guide/index.html[docs.confluent.io: Streams Developer Guide]
- https://www.confluent.io/blog/stream-processing-part-1-tutorial-developing-streaming-applications[Getting Your Feet Wet with Stream Processing (Confluent tutorials)]
- Исходники!
** https://github.com/apache/kafka/
** https://github.com/spring-projects/spring-kafka

== Сообщества, конференции
- Телеграм: Грефневая Кафка
** https://t.me/AwesomeKafka_ru
** https://t.me/proKafka
- Kafka Summit Conference: https://kafka-summit.org/

== Всё, что я показывал, есть на гитхабе

[cols="30a,70a"]
|===
.^|image::octocat.jpg[]
.^|
* Слайды: https://inponomarev.github.io/kstreams-examples[inponomarev.github.io/kstreams-examples]

* Исходники: https://github.com/inponomarev/kstreams-examples[github.com/inponomarev/kstreams-examples]
|===


== Полная версия доклада на JUG.MSK

[cols="30a,70a"]
|===
.^|image::jugmsk.jpg[]
.^|
* Часть I: https://youtu.be/PqQax9zur9I
* Часть II: https://youtu.be/pipM6bwQjoM
|===


== На этом всё!

icon:github[size=lg] https://github.com/inponomarev/kstreams-examples[inponomarev/kstreams-examples]

icon:twitter[size=lg] https://twitter.com/inponomarev[@inponomarev]

ponomarev@corchestra.ru

*Спасибо!*
