= Kafka Streams API: Шаг за рамки Hello World (краткая версия)
Иван Пономарёв, КУРС/МФТИ
:revealjs_theme: black
:revealjs_customtheme: white_course.css
:revealjs_transition: none
:revealjs_slideNumber:
:revealjs_history:
:revealjs_progress:
:encoding: UTF-8
:lang: ru
include::_doc_general_attributes.adoc[]
:doctype: article
:toclevels: 3
:imagesdir: images
:source-highlighter: pygments
//:highlightjsdir: highlight
:icons: font
:iconfont-remote!:
:iconfont-name: font-awesome-4.7.0/css/font-awesome
:revealjs_mouseWheel: true
:revealjs_center: false
:revealjs_width: 1600
:revealjs_height: 900


//== Часть 1. Введение
:!figure-caption:

ponomarev@corchestra.ru

icon:twitter[size=lg] @inponomarev

[%notitle]
== Кто я такой

[cols="30a,70a"]
|===
.^|image::me.jpg[]
.^|
* Tech Lead at KURS
* ERP systems & Java background
* Speaker at JPoint, Devoops, Heisenbug, JUG.MSK, PermDevDay, DevopsForum, Стачка etc.
* Текущий проект: Real-time Webscraping
|===

== Зачем нам Kafka?

image::kafka.jpg[{image-30-width}]

== Зачем нам Kafka?

[%step]
* Web-scraping в реальном времени
* 500 запросов/сек (да, это очень мало!)
* Удобные штуки «из коробки»:
** Персистентный, но «подрезаемый» лог
** Microbatching
** Streams API!

== Зачем нам Streams API?

[%step]
* Легкое масштабирование (чем больше worker-ов, тем быстрее)
* Устойчивость к потере worker-а (репликация внутреннего состояния)


== Когда меня спрашивают, какой стриминговый фреймворк использовать

image::weuseflink.jpg[{image-60-width}]


== Disclaimers

1. Предполагается базовое понимание Кафки

** https://www.youtube.com/watch?v=A_yUaPARv8U[Григорий Кошелев — Когда всё пошло по Кафке (JPoint 2019)]

2. Доклад не о жизни в production!

** https://www.youtube.com/watch?v=wCCR1Tkxc-s[Никита Сальников-Тарновский — Streaming architecture — шаг за рамки примеров кода (devclub.eu 2019.03.26)]
** То же самое на Joker 2019: https://jokerconf.com/2019/talks/2qw2ljhlfoeiipjf0gfzzb/[Потоковое приложение — это не только код, но и 3-4 года поддержки в проде]

== Kafka Streams API: общая структура KStreams-приложения

[source,java,highlight='1,4,6']
----
StreamsConfig config = ...;
//Здесь устанавливаем всякие опции

Topology topology = new StreamsBuilder()
//Здесь строим топологию
    ....build();
----

== Kafka Streams API: общая структура KStreams-приложения
Топология -- конвейер обработчиков:

[graphviz,"topology-sample.png"]
----
digraph G {

graph [ dpi = 140 ];
rankdir="LR";
node [shape="circle" fontsize=14; fixedsize="true"; width="1.3" ];


a[label="source"];
b[label="source"];
c[label="branch /\nsplit"];

d[label="process"];
e[label="join /\nmerge"];
f[label="sink"];
g[label="sink"];
{rank = same; a; b;}
a->c;
b->e;
c->e;
c->d;
d->f;
e->g;

}
----

== Kafka Streams API: общая структура KStreams-приложения

[source,java,highlight='9-13']
----
StreamsConfig config = ...;
//Здесь устанавливаем всякие опции

Topology topology = new StreamsBuilder()
//Здесь строим топологию
....build(); 


//Это за нас делает SPRING-KAFKA
KafkaStreams streams = new KafkaStreams(topology, config); 
streams.start(); 
...
streams.close();

----

== Легенда

[cols="30a,70a"]
|===
.^|image::betting.jpg[]
.^|
* Идут футбольные матчи (меняется счёт)
* Делаются ставки: H, D, A.
* Поток ставок, ключ: `Cyprus-Belgium:A`
* Поток ставок, значение:
[source,java]
----
class Bet {
  String bettor;   //John Doe
  String match;    //Cyprus-Belgium
  Outcome outcome; //A (or H or D)
  long amount;     //100
  double odds;     //1.7
  long timestamp;  //1554215083998
}
----
|===

== @Bean Topology
[graphviz, "yelling-topology1.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="1.1"];
Source[style=filled; fillcolor="#ffffcc"];
Source -> MapVal -> Sink

}
-----

[source,java,highlight='3-4']
----
@Bean
public Topology createTopology(StreamsBuilder streamsBuilder) {
  KStream<String, Bet> input = streamsBuilder.stream(
     BET_TOPIC, Consumed.with(Serdes...);
  KStream<String, Long> gain = input.mapValues(
              v -> Math.round(v.getAmount() * v.getOdds()));
  gain.to(GAIN_TOPIC, Produced.with(Serdes.String(),
                new JsonSerde<>(Long.class)));
  return streamsBuilder.build();
}
----


== @Bean Topology
[graphviz, "yelling-topology2.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="1.1"];
MapVal[style=filled; fillcolor="#ffffcc"];

Source -> MapVal -> Sink

}
-----

[source,java,highlight='5-6']
----
@Bean
public Topology createTopology(StreamsBuilder streamsBuilder) {
  KStream<String, Bet> input = streamsBuilder.stream(
     BET_TOPIC, Consumed.with(Serdes...);
  KStream<String, Long> gain = input.mapValues(
              v -> Math.round(v.getAmount() * v.getOdds()));
  gain.to(GAIN_TOPIC, Produced.with(Serdes.String(),
                new JsonSerde<>(Long.class)));
  return streamsBuilder.build();
}
----


== @Bean Topology
[graphviz, "yelling-topology3.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="1.1"];
Sink[style=filled; fillcolor="#ffffcc"];

Source -> MapVal -> Sink

}
-----

[source,java,highlight='7-8']
----
@Bean
public Topology createTopology(StreamsBuilder streamsBuilder) {
  KStream<String, Bet> input = streamsBuilder.stream(
     BET_TOPIC, Consumed.with(Serdes...);
  KStream<String, Long> gain = input.mapValues(
              v -> Math.round(v.getAmount() * v.getOdds()));
  gain.to(GAIN_TOPIC, Produced.with(Serdes.String(),
                new JsonSerde<>(Long.class)));
  return streamsBuilder.build();
}
----

== Как проверить, что оно считает правильно?

`TopologyTestDriver` to the resque!

== TopologyTestDriver: создание

[source,java,highlight='1-2,5-6']
----
KafkaStreamsConfiguration config = new KafkaConfiguration()
                                        .getStreamsConfig();
StreamsBuilder sb = new StreamsBuilder();

Topology topology = 
    new TopologyConfiguration().createTopology(sb);

//Наличие настоящей Кафки не требуется
TopologyTestDriver topologyTestDriver = 
        new TopologyTestDriver(topology, 
                               config.asProperties());
----

== TopologyTestDriver: создание

[source,java,highlight='8-11']
----
KafkaStreamsConfiguration config = new KafkaConfiguration()
                                        .getStreamsConfig();
StreamsBuilder sb = new StreamsBuilder();

Topology topology = 
    new TopologyConfiguration().createTopology(sb);

//Наличие настоящей Кафки не требуется
TopologyTestDriver topologyTestDriver = 
        new TopologyTestDriver(topology, 
                               config.asProperties());
----

== TopologyTestDriver: использование

[source,java,highlight='8']
----
Bet bet = Bet.builder()
            .bettor("John Doe")
            .match("Germany-Belgium")
            .outcome(Outcome.H)
            .amount(100)
            .odds(1.7).build();

topologyTestDriver.pipeInput(
    betFactory.create(BET_TOPIC, bet.key(), bet));
----

== TopologyTestDriver: использование

[source,java,highlight='2']
----
ProducerRecord<String, Long> record =
   topologyTestDriver.readOutput(
        GAIN_TOPIC, 
        new StringDeserializer(),
        new JsonDeserializer<>(Long.class)
    );

assertEquals(bet.key(), record.key());
assertEquals(170L, record.value().longValue());
----

== TopologyTestDriver: использование

[source,java,highlight='8,9']
----
ProducerRecord<String, Long> record =
   topologyTestDriver.readOutput(
        GAIN_TOPIC, 
        new StringDeserializer(),
        new JsonDeserializer<>(Long.class)
    );

assertEquals(bet.key(), record.key());
assertEquals(170L, record.value().longValue());
----

== Как понять, что граф топологии построен правильно?

* Метод `describe()`
[source,java]
System.out.println(topology.describe());
* Kafka Streams Topology Visualizer (https://zz85.github.io/kafka-streams-viz/)

== Визуализация топологии

image::visualizer.png[{image-50-width}]


== Локальное состояние

[.custom-style]
[cols="25a,75a"]
|===
.^|image::rocksdb.png[{image-80-width}]
.^|
* Facebook's RocksDB
** Embedded key/value storage
** High-performant (data locality)
** Persistent, optimized for SSD
* По функционалу похож на `TreeMap<K,V>`!
|===

== Пишем “Bet Totalling App”

Какова сумма выплат по сделанным ставкам, если сыграет исход?

== @Bean Topology

[graphviz, "counting-topology1.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Source[style=filled; fillcolor="#ffffcc"];
Store [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.5"]
Source -> MapVal -> Sum -> Sink
Sum -> Store [dir=both; label=" \n "]
{rank = same; Store; Sum;}
}
-----

[source,java,highlight='2']
----
KStream<String, Bet> input = streamsBuilder.
    stream(BET_TOPIC, Consumed.with(Serdes.String(),
                      new JsonSerde<>(Bet.class)));
----

== @Bean Topology

[graphviz, "counting-topology2.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
MapVal[style=filled; fillcolor="#ffffcc"];
Store [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.5"]
Source -> MapVal -> Sum -> Sink
Sum -> Store [dir=both; label=" \n "]
{rank = same; Store; Sum;}
}
-----

[source,java,highlight='3']
----
KStream<String, Long> gain
    = input.mapValues(
      v -> Math.round(v.getAmount() * v.getOdds()));

//Key: "Germany-Belgium:H"
//Value: 170L
----

== @Bean Topology

[graphviz, "counting-topology3.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Sum[style=filled; fillcolor="#ffffcc"];
Store [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.5";style=filled; fillcolor="#ffffcc"]
Source -> MapVal -> Sum -> Sink
Sum -> Store [dir=both; label=" \n "]
{rank = same; Store; Sum;}
}
-----

[source,java,highlight='3']
----
KStream<String, Long> counted =
    new TotallingTransformer()
            .transformStream(streamsBuilder, gain);
----


== TotallingTransformer
[source,java,highlight='4-6']
----
@Override
public KeyValue<String, Long> transform(String key, Bet value,
                    KeyValueStore<String, Long> stateStore) {
    long current = Optional
        .ofNullable(stateStore.get(key))
        .orElse(0L);
    current += value.getAmount();
    stateStore.put(key, current);
    return KeyValue.pair(key, current);
}
----

== TotallingTransformer
[source,java,highlight='7']
----
@Override
public KeyValue<String, Long> transform(String key, Bet value,
                    KeyValueStore<String, Long> stateStore) {
    long current = Optional
        .ofNullable(stateStore.get(key))
        .orElse(0L);
    current += value.getAmount();
    stateStore.put(key, current);
    return KeyValue.pair(key, current);
}
----

== TotallingTransformer
[source,java,highlight='8']
----
@Override
public KeyValue<String, Long> transform(String key, Bet value,
                    KeyValueStore<String, Long> stateStore) {
    long current = Optional
        .ofNullable(stateStore.get(key))
        .orElse(0L);
    current += value.getAmount();
    stateStore.put(key, current);
    return KeyValue.pair(key, current);
}
----


== StateStore доступен в тестах
[source,java,highlight='8,10,11']
----
@Test
void testTopology() {
    topologyTestDriver.pipeInput(...);
    topologyTestDriver.pipeInput(...);

    KeyValueStore<String, Long> store =
        topologyTestDriver
        .getKeyValueStore(TotallingTransformer.STORE_NAME);
    
    assertEquals(..., store.get(...));
    assertEquals(..., store.get(...));
}
----


== Демо: Ребалансировка / репликация

* Ребалансировка / репликация партиций state при запуске / выключении обработчиков.


== Сохранение локального состояния в{nbsp}топик

[source,code]
----
$kafka-topics --zookeeper localhost --describe

Topic:bet-totalling-demo-app-totalling-store-changelog
PartitionCount:10       
ReplicationFactor:1 
Configs:cleanup.policy=compact
----


== Мы думали, картина такая...
[graphviz, "counting-topology-changelog1.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Store [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.5"]
Source -> MapVal -> Sum -> Sink
Sum -> Store [dir=both; label=" \n "]
{rank = same; Store; Sum;}
Store -> Changelog[style="invis"]
Changelog[shape="box"; style="invis"; width="1.5"; fillcolor="#ffffcc"]
}
-----

== ...но на самом деле она вот какая:
[graphviz, "counting-topology-changelog2.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Store [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.5"]
Source -> MapVal -> Sum -> Sink
Sum -> Store [dir=both; label=" \n "]
{rank = same; Store; Sum;}
Store -> Changelog
Changelog[shape="box"; style="filled"; width="1.5"; fillcolor="#ffffcc"]
}
-----

== Партиционирование и local state
[graphviz, "local-partitioning-oneworker.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {

     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source"];
          S2 [shape=plaintext label = "Local store"];
          S3 [shape=plaintext label = "Changelog"];
          S1->S2->S3 [style="invis"]
      }

    subgraph cluster_p1 {
      label = "Worker 1";
        
        subgraph cluster_pp2{
              label = "Partition 3"
                
              d[label = "D"];
              
              
          }
          
          
        d->ls1;
        
        ls1->p3[dir="both"];
          
          subgraph cluster_pp11{
              label = "Partition 2"
          
              b [label = "B"];
              c[label = "C"];
              
          }
 
        subgraph cluster_pp1{
              label = "Partition 1"
              
              
              a [label = "A"];
              
          }
          
        
        ls1[shape="cylinder" label = "RocksDB"]
        a->ls1;
        b->ls1;
        c->ls1;
        
        p1[shape="plaintext"; style="filled"; fillcolor="#ffffcc"; label = "Partition 2"];
        p2[shape="plaintext"; style="filled"; fillcolor="#ffffcc"; label = "Partition 3"];
        p3[shape="plaintext"; style="filled"; fillcolor="#ffffcc"; label = "Partition 1"];
        ls1->p1[dir="both"];
        ls1->p2[dir="both"];
        
        
    }

    
    
  }
} 
-----

== Партиционирование и local state
[graphviz, "local-partitioning.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {

     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source"];
          S2 [shape=plaintext label = "Local store"];
          S3 [shape=plaintext label = "Changelog"];
          S1->S2->S3 [style="invis"]
      }

    subgraph cluster_p1 {
      label = "Worker 1";
        
          
          subgraph cluster_pp11{
              label = "Partition 2"
          
              b [label = "B"];
              c[label = "C"];
              
          }
 
        subgraph cluster_pp1{
              label = "Partition 1"
              
              
              a [label = "A"];
              
          }
          
        
        ls1[shape="cylinder" label = "RocksDB"]
        a->ls1;
        b->ls1;
        c->ls1;
        
        p1[shape="plaintext"; style="filled"; fillcolor="#ffffcc"; label = "Partition 1"];
        p2[shape="plaintext"; style="filled"; fillcolor="#ffffcc"; label = "Partition 2"];
        ls1->p1[dir="both"];
        ls1->p2[dir="both"];
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 3"
                
              d[label = "D"];
              
              
          }
          
          
        ls2[shape="cylinder" label = "RocksDB"]
        d->ls2;
        p3[shape="plaintext"; style="filled"; fillcolor="#ffffcc"; label = "Partition 3"];
        ls2->p3[dir="both"];
    }
    
    
  }
} 
-----

// == Подробнее о ребалансировке
// 
// [cols="30a,70a"]
// |===
// .^|image::matthias.jpg[]
// .^|
// *Matthias J. Sax* // https://www.confluent.io/kafka-summit-lon19/everyth// ing-you-wanted-to-know-kafka-afraid[Everything You // Always Wanted to Know About Kafka’s Rebalance // Protocol but Were Afraid to Ask (Kafka Summit // London, 2019)]
// |===


== Репартиционирование
[graphviz, "through.png"]
-----
digraph G
{
    graph [ dpi = 150 ]; 
    rankdir="LR";
    node [shape=record, width=.1, height=.1];
    node1 [label="{ | | | | }", fontsize = 18, xlabel= "through(. . .)"];
    
    node [label = " "; shape="circle"; fixedsize="true"; width="1.1"];
    Source -> node1
    node1 -> Sink
    
}
-----

* Неявное при операциях, меняющих ключ + stateful-операциях
* Явное при помощи +
`through(String topic, Produced<K, V> produced)`


== Дублирующееся неявное репартиционирование
[source,java]
----
KStream source = builder.stream("topic1");
KStream mapped = source.map(...);
KTable counts = mapped.groupByKey().aggregate(...);
KStream sink = mapped.leftJoin(counts, ...);
----

[graphviz, "doublethrough.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="0.8"; label=""];
Start, Finish [style="invis"]
Start -> A
A[label="map"]
A -> throughAgg  [style=dashed]
throughAgg -> Agg  [style=dashed]
A -> throughJoin [style=dashed]
throughJoin -> Join [style=dashed]
Agg[label="Agg"]
Join[label="Join"]
Agg -> Join
Join -> Finish
Store [shape="cylinder"; label="Store";]
Agg -> Store [dir="both"]
throughAgg [shape="record"; label="{ | | | | }"; height = "0.2"]
throughJoin [shape="record"; label="{ | | | | }"; height = "0.2"]
}
-----

== Избавляемся от дублирующегося репартиционирования

[source,java]
----
KStream source = builder.stream("topic1");
KStream shuffled = source.map(...).through("topic2",..);
KTable counts = shuffled.groupByKey().aggregate(...);
KStream sink = shuffled.leftJoin(counts, ...);
----

[graphviz, "implicitthrough.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=16; shape="circle"; fixedsize="true"; width="0.8"; label=""];
Start, Finish [style="invis"]
Start -> A
A[label="map"]
A -> throughAgg
throughAgg[xlabel="through"]
throughAgg -> Agg
throughAgg -> Join
Agg[label="Agg"]
Join[label="Join"]
Agg -> Join
Join -> Finish
Store [shape="cylinder"; label="Store";]
Agg -> Store [dir="both"]
throughAgg [shape="record"; label="{ | | | | }"; height = "0.2"]
}
-----

// == Ключ лучше лишний раз не трогать
// 
// *Key only:* `selectKey`
// 
// [cols=2*] 
// |===
// |*Key and Value*
// |*Value Only*
// 
// |`map`
// |`mapValues`
// 
// |`flatMap`
// |`flatMapValues`
// 
// |`transform`
// |`transformValues`
// 
// |`flatTransform`
// |`flatTransformValues`
// 
// 
// |===
// 
// == Подробнее про «лишнее» репартиционирование
// 
// [cols="30a,70a"]
// |===
// .^|image::guozhang.jpeg[]
// .^|
// *Guozhang Wang* // https://www.confluent.io/kafka-summit-lon19/perform// ance-analysis-optimizations-kafka-streams-applicati// ons[Performance Analysis and Optimizations for // Kafka Streams Applications (Kafka Summit London, // 2019)]
// |===


// == Таблицы vs стримы
// 
// Местонахождение пользователя
// 
// .Michael G. Noll. Of Streams and Tables in Kafka and Stream Processing
// image::stream-table-animation-latestLocation.gif[{image-100-width}]
// 
// 
// == Таблицы vs стримы
// 
// Количество посещенных мест
// 
// .Michael G. Noll. Of Streams and Tables in Kafka and Stream Processing
// image::stream-table-animation-numVisitedLocations.gif[{image-100-width}// ]


== Таблицы vs стримы

Производная и интеграл

.Martin Kleppmann, “Designing Data Intensive Applications”
image::derivative-and-integral.png[{image-100-width}]

== Переписываем totalling app при помощи KTable

[source,java,highlight='3']
----
KTable<String, Long> totals = input.groupByKey().aggregate(
    () -> 0L, 
    (k, v, a) -> a + Math.round(v.getAmount() * v.getOdds()),
    Materialized.with(Serdes.String(), Serdes.Long())
);
----

== Переписываем totalling app при помощи KTable

[source,java,highlight='4']
----
KTable<String, Long> totals = input.groupByKey().aggregate(
    () -> 0L, 
    (k, v, a) -> a + Math.round(v.getAmount() * v.getOdds()),
    Materialized.with(Serdes.String(), Serdes.Long())
);
----

[source,code]
----
$kafka-topics --zookeeper localhost --describe

Topic: 
table2-demo-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog 
PartitionCount:10
ReplicationFactor:1
Configs:cleanup.policy=compact
----


== Виды Join-ов: Table-Table

image::table-table.svg[{image-40-width}]

== Виды Join-ов: Table-Table

image::table-table1.svg[{image-40-width}]

== Виды Join-ов: Table-Table

image::table-table2.svg[{image-40-width}]


== Виды Join-ов: Stream-Table

image::stream-table.svg[{image-40-width}]


== Получаем таблицу счетов матчей

[source,java,highlight='7-12']
----
KStream<String, EventScore> eventScores =
    streamsBuilder.stream(EVENT_SCORE_TOPIC,
                Consumed.with(Serdes.String(), 
                new JsonSerde<>(EventScore.class)
                ));
        /*  ключ не пригоден для join-а с суммой ставок
            Key: Germany-Belgium
            Value: EventScore {
                     event     = Germany-Belgium;
                     score     = 1:0;
                     timestamp = 554215083998;
             }
         */
----

== Получаем таблицу счетов матчей

[source,java,highlight='2,8-9,11-12']
----
KStream<String, Score> scores = eventScores
    .flatMap((k, v) ->
        Stream.of(Outcome.H, Outcome.A).map(o ->
            KeyValue.pair(
                    String.format("%s:%s", k, o), v))
            .collect(Collectors.toList()))
    /*
        Key: Germany-Belgium:H
        Value: EventScore
        
        Key: Germany-Belgium:A
        Value: EventScore
    */
    .mapValues(EventScore::getScore);

----

== Превращаем поток в таблицу
[source,java,highlight='5']
----
KTable<String, Score> tableScores =
    scores.groupByKey(
        Grouped.with(Serdes.String(), 
                     new JsonSerde<>(Score.class)))
    .reduce((a, b) -> b);
----

== Получаем таблицу счетов матчей

[source,java,highlight='6-7']
----
KTable<String, String> joined = 
    totals.join(tableScores,
            (total, eventScore) -> 
                String.format("(%s)\t%d", eventScore, total));
                
/*Key: Germany-Belgium:H
  Value: (1:0) 171340*/
----

== Демо: join() и leftJoin() 

== Копартиционирование

Join работает

[graphviz, "copart-norm.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "Source 2"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        
          
          subgraph cluster_pp11{
              label = "Partition 2"
          
              b [label = "B"];
              c[label = "C"];
              
          }
          subgraph cluster_pp12{
              label = "Partition 2"
              labelloc ="b"
          
              b1 [label = "B"];
              
              c1[label = "C"];
          }
          
          subgraph cluster_p1{
              label = "Partition 1"
          labelloc = "b"
              
              a1 [label = "A"]
              
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
              
              
              a [label = "A"];
              
          }
          
          a->a1[style="dashed" dir="none"];
          b->b1[style="dashed" dir="none"];
          c->c1[style="dashed" dir="none"];
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 3"
                
              d[label = "D"];
              
              
          }
          subgraph cluster_p2{
              label = "Partition 3"
              labelloc = "b"
              d1[label = "D"];
              
              
          }
          
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

== Несовпадение количества партиций

Join не работает (Runtime Exception)

[graphviz, "copart-diff.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "Source 2"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        subgraph cluster_p1{
              label = "Partition 1"
              labelloc = "b"
              b1 [label = "B"]
              a1 [label = "A"]
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
          
              
              a [label = "A"];
              
          }
          
          subgraph cluster_pa2{
              label = "Partition 2"
          b [label = "B"];
              c [label = "C" color="red"];
              
          }
          a->a1[style="dashed" dir="none"];
          b->b1[style="dashed" dir="none"];
          
          
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 3"
          
              d[label = "D"];
              
              
          }
          subgraph cluster_pa3{
              label = "Partition 2"
              labelloc = "b"
          
              d1[label = "D"];
              c1[label = "C" color ="red"];
              
          }
          c->c1[ dir="none" color="red"];
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

== Несовпадение алгоритма партицирования

Join не работает молча!

[graphviz, "copart-diff-algorithm.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "Source 2"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        subgraph cluster_p1{
              label = "Partition 1"
              labelloc = "b"
          
              b1 [label = "B" color="red"]
              a1 [label = "A"]
              
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
          
               c[label = "C" color= "red"];
              a [label = "A"];
              
          }
          
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 2"
          b [label = "B" color="red"];
              d[label = "D"];
             
              
          }
          subgraph cluster_p2{
              label = "Partition 2"
              labelloc = "b"
              d1[label = "D"];
              c1[label = "C" color = "red"];
              
          }
          a->a1[style="dashed" dir="none"];
          b->b1[color="red" dir="none"];
          c->c1[color="red" dir="none"];
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

== GlobalKTable

Реплицируется всюду целиком

[source,java]
----
GlobalKTable<...> global = streamsBuilder.globalTable("global", ...);
----

[graphviz, "globalktable.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "GlobalKTable"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        subgraph cluster_p1{
              label = ""
          
              b1 [label = "B"]
              a1 [label = "A"]
              cc [label = "C"] 
              dd [label = "D"]
              a1->cc[style="invis"];
              b1->dd[style="invis"];
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
          
             
              a [label = "A"];
              b [label = "B"];
          }
          
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 2"
                c[label = "C"];
              
              d[label = "D"];
              
             
              
          }
          subgraph cluster_p2{
              label = ""
              labelloc = "b"
              d1[label = "D"];
              c1[label = "C" ];
              aa[label = "A"];
              bbb[label = "B"];
              c1->aa [style= "invis"];
              d1->bbb [style= "invis"];
              
          }
          a->a1[style="dashed" dir="none"];
          b->b1[style="dashed" dir="none"];
          c->c1[style="dashed" dir="none"];
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

== Виды Join-ов: оконный Stream-Stream

image::stream-stream.svg[{image-40-width}]



== Сохранение Timestamped-значений в{nbsp}RocksDB

WindowKeySchema.java

[source,java,highlight='8-10']
----
static Bytes toStoreKeyBinary(byte[] serializedKey,
                              long timestamp,
                              int seqnum) {
    ByteBuffer buf = ByteBuffer.allocate(
                                serializedKey.length
                                + TIMESTAMP_SIZE 
                                + SEQNUM_SIZE);
    buf.put(serializedKey);
    buf.putLong(timestamp);
    buf.putInt(seqnum);
    return Bytes.wrap(buf.array());
}
----

== Быстрое извлечение значений по ключу из диапазона времени

[graphviz, "timestamped-record.png"]
-----
digraph G
{
    graph [ dpi = 150 ]; 
    node [shape=record, fontsize=18];
    node0 [label="..."];
    node1 [label="<f0> key|<f1> timestamp|<f2> seqnum"];
    node2 [label="..."];
    node0 -> node1;
    node0 -> node2;
}
-----

== Демо: Windowed Joins

* «Послегольщик» — игрок, пытающийся протолкнуть правильную ставку в момент смены счёта в матче
* Штамп времени ставки и события смены счёта должны «почти совпадать».

image::livebet.jpg[{image-50-width}]

== Время, вперёд!

[source,java,highlight='4-6']
----
KStream<String, Bet> bets = streamsBuilder.stream(BET_TOPIC,
    Consumed.with(
            Serdes...)
            .withTimestampExtractor(
                (record, previousTimestamp) ->
                    ((Bet) record.value()).getTimestamp()
            ));
----
(Ещё время можно извлечь из WallClock и RecordMetadata.)


== Из событий смены счёта фомируем поток "surebets"
[source,java,highlight='4-5']
----
@Override
public KeyValue<String, Bet> transform (String key, 
  EventScore value, KeyValueStore<..> stateStore) {
  Score current = Optional.ofNullable(stateStore.get(key))
                .orElse(new Score());
  stateStore.put(key, value.getScore());
  Outcome currenOutcome = 
    value.getScore().getHome() > current.getHome() 
    ?
    Outcome.H : Outcome.A;
  Bet bestBet = new Bet(null, value.getEvent(), 
               currenOutcome, 0, 1, value.getTimestamp());
  return KeyValue.pair(
    String.format("%s:%s", key, currenOutcome)
    , bestBet);
}
----

== Из событий смены счёта фомируем поток "surebets"
[source,java,highlight='6']
----
@Override
public KeyValue<String, Bet> transform (String key, 
  EventScore value, KeyValueStore<..> stateStore) {
  Score current = Optional.ofNullable(stateStore.get(key))
                .orElse(new Score());
  stateStore.put(key, value.getScore());
  Outcome currenOutcome = 
    value.getScore().getHome() > current.getHome() 
    ?
    Outcome.H : Outcome.A;
  Bet bestBet = new Bet(null, value.getEvent(), 
               currenOutcome, 0, 1, value.getTimestamp());
  return KeyValue.pair(
    String.format("%s:%s", key, currenOutcome)
    , bestBet);
}
----

== Из событий смены счёта фомируем поток "surebets"
[source,java,highlight='7-10']
----
@Override
public KeyValue<String, Bet> transform (String key, 
  EventScore value, KeyValueStore<..> stateStore) {
  Score current = Optional.ofNullable(stateStore.get(key))
                .orElse(new Score());
  stateStore.put(key, value.getScore());
  Outcome currenOutcome = 
    value.getScore().getHome() > current.getHome() 
    ?
    Outcome.H : Outcome.A;
  Bet bestBet = new Bet(null, value.getEvent(), 
               currenOutcome, 0, 1, value.getTimestamp());
  return KeyValue.pair(
    String.format("%s:%s", key, currenOutcome)
    , bestBet);
}
----


== Из событий смены счёта фомируем поток "surebets"
[source,java,highlight='14']
----
@Override
public KeyValue<String, Bet> transform (String key, 
  EventScore value, KeyValueStore<..> stateStore) {
  Score current = Optional.ofNullable(stateStore.get(key))
                .orElse(new Score());
  stateStore.put(key, value.getScore());
  Outcome currenOutcome = 
    value.getScore().getHome() > current.getHome() 
    ?
    Outcome.H : Outcome.A;
  Bet bestBet = new Bet(null, value.getEvent(), 
               currenOutcome, 0, 1, value.getTimestamp());
  return KeyValue.pair(
    String.format("%s:%s", key, currenOutcome)
    , bestBet);
}
----


== Демо: Windowed Joins
[source, java,highlight='1,8']
----
KStream<String, String> join = bets.join(winningBets,
    (bet, winningBet) ->
            String.format("%s bet %s=%s %d",
                    bet.getBettor(),
                    bet.getOutcome(),
                    winningBet.getOutcome(),
                    winningBet.getTimestamp() - bet.getTimestamp()),
    JoinWindows.of(Duration.ofSeconds(1)).before(Duration.ZERO),
    Joined.with(Serdes.String(),
            new JsonSerde<>(Bet.class),
            new JsonSerde<>(Bet.class)
    ));
----

== Без тестов не разберёшься!

[source,java,highlight='9,13']
----
@Test
public void nearBetsFound() {
  long current = System.currentTimeMillis();
  putScore(new EventScore(
    "Turkey-Moldova", new Score().goalHome(), current));
  putBet(new Bet(
    "alice", "Turkey-Moldova", Outcome.A, 1, 1.5, current - 100));
  putBet(new Bet(
    "bob", "Turkey-Moldova", Outcome.H, 1, 1.5, current - 100));
  putBet(new Bet(
    "bob", "Turkey-Moldova", Outcome.H, 1, 1.5, current - 5000));
  assertEquals(
    Arrays.asList("Turkey-Moldova:H-bob bet H=H 100"), output);
}
----

== Tumbling, Hopping & Session-окна для агрегации

[cols="33a,33a,33a"]
|===
| image::tumbling-window.png[] | image::hopping-window.png[] | image::streams-session-windows-02.png[]
|===



== Kafka Streams in Action

[.custom-style]
[cols="30a,70a"]
|===
|image::KSIA.jpg[]
|
* **William Bejeck**, + 
“Kafka Streams in Action”, November 2018
* Примеры кода для Kafka 1.x
|===

== Сообщества, конференции
- Телеграм: Грефневая Кафка
** https://t.me/AwesomeKafka_ru
** https://t.me/proKafka
- Kafka Summit Conference: https://kafka-summit.org/

== Всё, что я показывал, есть на гитхабе

[cols="30a,70a"]
|===
.^|image::octocat.jpg[]
.^|
* Слайды: https://inponomarev.github.io/kstreams-examples[inponomarev.github.io/kstreams-examples]

* Исходники: https://github.com/inponomarev/kstreams-examples[github.com/inponomarev/kstreams-examples]
|===


== Полная версия доклада на JUG.MSK

[cols="30a,70a"]
|===
.^|image::jugmsk.jpg[]
.^|
* Часть I: https://youtu.be/PqQax9zur9I
* Часть II: https://youtu.be/pipM6bwQjoM
|===


== На этом всё!

icon:github[size=lg] https://github.com/inponomarev/kstreams-examples[inponomarev/kstreams-examples]

icon:twitter[size=lg] https://twitter.com/inponomarev[@inponomarev]

ponomarev@corchestra.ru

*Спасибо!*
